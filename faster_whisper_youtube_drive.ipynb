{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamed-jamali-software/mp32face/blob/main/faster_whisper_youtube_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Youtube/Google Drive Videos Translation/Transcription with Faster Whisper**\n",
        "\n",
        "[faster-whisper](https://github.com/guillaumekln/faster-whisper) is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models.\n",
        "\n",
        "This implementation is up to 4 times faster than openai/whisper for the same accuracy while using less memory. The efficiency can be further improved with 8-bit quantization on both CPU and GPU.\n",
        "\n",
        "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.\n",
        "\n",
        "This Notebook will guide you through the transcription or translation of a  video file (from Youtube/Google Drive) using Faster Whisper. You'll be able to explore most inference parameters or use the Notebook as-is to store the output and video audio in your Google Drive.\n",
        "\n",
        "## **How to use**\n",
        "1. Read and understand the notebook. You should at the very least modify the **video selection section** to choose the video you wish to translate/transcribe\n",
        "2. Click Runtime -> Run all and wait for the notebook to do its magic, alternatively you may run the cells one by one and skip the Google Drive portion if you do not intend to use it\n",
        "3. A download prompt should appear once subtitles is ready, or check the 'Files' tab on the left for the output\n"
      ],
      "metadata": {
        "id": "96kvih9mXkNN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zwGAsr4sIgd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **[Optional]** Access data in Google Drive üíæ\n",
        "#@markdown Enter a Google Drive path and run this cell to store the results inside Google Drive.\n",
        "\n",
        "# Uncomment to copy generated images to drive, faster than downloading directly from colab in my experience.\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "drive_mount_path = Path(\"/\") / \"content\" / \"drive\"\n",
        "drive.mount(str(drive_mount_path))\n",
        "drive_mount_path /= \"My Drive\"\n",
        "#@markdown ---\n",
        "drive_path = \"Colab Notebooks/Faster Whisper\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change your Google Drive path.**\n",
        "\n",
        "drive_whisper_path = drive_mount_path / Path(drive_path.lstrip(\"/\"))\n",
        "drive_whisper_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Check GPU type** üïµÔ∏è\n",
        "\n",
        "#@markdown The type of GPU you get assigned in your Colab session defined the speed at which the video will be transcribed.\n",
        "#@markdown The higher the number of floating point operations per second (FLOPS), the faster the transcription.\n",
        "#@markdown But even the least powerful GPU available in Colab is able to run any Whisper model.\n",
        "#@markdown Make sure you've selected `GPU` as hardware accelerator for the Notebook (Runtime &rarr; Change runtime type &rarr; Hardware accelerator).\n",
        "\n",
        "#@markdown |  GPU   |  GPU RAM   | FP32 teraFLOPS |     Availability   |\n",
        "#@markdown |:------:|:----------:|:--------------:|:------------------:|\n",
        "#@markdown |  T4    |    16 GB   |       8.1      |         Free       |\n",
        "#@markdown | P100   |    16 GB   |      10.6      |      Colab Pro     |\n",
        "#@markdown | V100   |    16 GB   |      15.7      |  Colab Pro (Rare)  |\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Factory reset your Notebook's runtime if you want to get assigned a new GPU.**\n",
        "\n",
        "!nvidia-smi -L\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "QshUbLqpX7L4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfG0E_WbRFI0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Install libraries** üèóÔ∏è\n",
        "#@markdown This cell will take a little while to download several libraries, including Faster Whisper.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "! pip install faster-whisper\n",
        "! pip install yt-dlp\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "from faster_whisper import WhisperModel\n",
        "import yt_dlp\n",
        "import subprocess\n",
        "import torch\n",
        "import shutil\n",
        "import numpy as np\n",
        "from IPython.display import display, Markdown, YouTubeVideo\n",
        "import requests\n",
        "from urllib.parse import urlsplit\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt install nvidia-cuda-toolkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Model selection** üß†\n",
        "\n",
        "#@markdown There are several models to choose from, with varying performance and speed. large-v2 is recommended for most cases:\n",
        "\n",
        "#@markdown |  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "#@markdown |:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "#@markdown |  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~0.8 GB     |      ~32x      |\n",
        "#@markdown |  base  |    74 M    |     `base.en`      |       `base`       |     ~1.0 GB     |      ~16x      |\n",
        "#@markdown | small  |   244 M    |     `small.en`     |      `small`       |     ~1.4 GB     |      ~6x       |\n",
        "#@markdown | medium |   769 M    |    `medium.en`     |      `medium`      |     ~2.7 GB     |      ~2x       |\n",
        "#@markdown | large-v1  |   1550 M   |        N/A         |      `large-v1`       |    ~4.3 GB     |       1x       |\n",
        "#@markdown | large-v2  |   1550 M   |        N/A         |      `large-v2`       |    ~4.3 GB     |       1x       |\n",
        "\n",
        "#@markdown ---\n",
        "model_size = 'large-v2' #@param ['tiny', 'tiny.en', 'base', 'base.en', 'small', 'small.en', 'medium', 'medium.en', 'large-v1', 'large-v2']\n",
        "device_type = \"cuda\" #@param {type:\"string\"} ['cuda', 'cpu']\n",
        "compute_type = \"float16\" #@param {type:\"string\"} ['float16', 'int8_float16', 'int8']\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the model.**\n",
        "\n",
        "model = WhisperModel(model_size, device=device_type, compute_type=compute_type)\n"
      ],
      "metadata": {
        "id": "TMhrSq_GZ6kA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # **Video selection** üì∫\n",
        "\n",
        "#@markdown Enter the URL of the Youtube video **OR** Google drive video path of the video you want to translate/transcribe, and run the cell. Make sure the correct Type is chosen! This may take awhile depending on video file size.\n",
        "\n",
        "Type = \"Youtube video or playlist\" #@param ['Youtube video or playlist', 'Google Drive', 'Direct download']\n",
        "#@markdown ---\n",
        "#@markdown #### **Youtube video or playlist**\n",
        "URL = \"https://www.youtube.com/watch?v=9ez8lm9I26Y\" #@param {type:\"string\"}\n",
        "# store_audio = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Google Drive video, audio (mp4, wav), or folder containing video and/or audio files**\n",
        "video_path = \"Colab Notebooks/my_video.mp4\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### **Direct Download**\n",
        "ddl_url = \"https://www.example.com/video.mkv\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown **Run this cell again if you change the video.**\n",
        "\n",
        "video_path_local_list = []\n",
        "\n",
        "if Type == \"Youtube video or playlist\":\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'm4a/bestaudio/best',\n",
        "        'outtmpl': '%(id)s.%(ext)s',\n",
        "        # ‚ÑπÔ∏è See help(yt_dlp.postprocessor) for a list of available Postprocessors and their arguments\n",
        "        'postprocessors': [{  # Extract audio using ffmpeg\n",
        "            'key': 'FFmpegExtractAudio',\n",
        "            'preferredcodec': 'wav',\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        error_code = ydl.download([URL])\n",
        "        list_video_info = [ydl.extract_info(URL, download=False)]\n",
        "\n",
        "    for video_info in list_video_info:\n",
        "        video_path_local_list.append(Path(f\"{video_info['id']}.wav\"))\n",
        "\n",
        "elif Type == \"Google Drive\":\n",
        "    # video_path_drive = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    video_path = drive_mount_path / Path(video_path.lstrip(\"/\"))\n",
        "    if video_path.is_dir():\n",
        "        for video_path_drive in video_path.glob(\"**/*\"):\n",
        "            if video_path_drive.is_file():\n",
        "                display(Markdown(f\"**{str(video_path_drive)} selected for processing.**\"))\n",
        "            elif video_path_drive.is_dir():\n",
        "                display(Markdown(f\"**Subfolders not supported.**\"))\n",
        "            else:\n",
        "                display(Markdown(f\"**{str(video_path_drive)} does not exist, skipping.**\"))\n",
        "            video_path_local = Path(\".\").resolve() / (video_path_drive.name)\n",
        "            shutil.copy(video_path_drive, video_path_local)\n",
        "            video_path_local_list.append(video_path_local)\n",
        "    elif video_path.is_file():\n",
        "        video_path_local = Path(\".\").resolve() / (video_path.name)\n",
        "        shutil.copy(video_path, video_path_local)\n",
        "        video_path_local_list.append(video_path_local)\n",
        "        print(f\"{video_path_local} appended to list for processing\")\n",
        "        display(Markdown(f\"**{str(video_path)} selected for processing.**\"))\n",
        "    else:\n",
        "        display(Markdown(f\"**{str(video_path)} does not exist.**\"))\n",
        "\n",
        "elif Type == \"Direct download\":\n",
        "    print(f\"‚ö†Ô∏è Please ensure this is a direct download link and is of a valid format\")\n",
        "    print(f\"Attempting to download: {ddl_url}\\n\")\n",
        "    # !wget {ddl_url} -O ddl_video.mp4\n",
        "    # video_path_local_list.append(\"/content/ddl_video.mp4\")\n",
        "\n",
        "    response = requests.get(ddl_url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Extract the filename from the URL\n",
        "        filename = urlsplit(ddl_url).path.split(\"/\")[-1]\n",
        "\n",
        "        # Create the full path for the destination file in the current working directory\n",
        "        destination_path = os.path.join(os.getcwd(), filename)\n",
        "\n",
        "        # Save the file\n",
        "        with open(destination_path, 'wb') as file:\n",
        "            file.write(response.content)\n",
        "\n",
        "        print(f\"File downloaded successfully: {destination_path}\")\n",
        "\n",
        "        video_path_local = Path(\".\").resolve() / (filename)\n",
        "\n",
        "        # print(f\"Path local: {video_path_local}\") # /content/video.mkv\n",
        "\n",
        "        video_path_local_list.append(video_path_local)\n",
        "    else:\n",
        "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
        "\n",
        "else:\n",
        "    raise(TypeError(\"Please select supported input type.\"))\n",
        "\n",
        "for video_path_local in video_path_local_list:\n",
        "    valid_suffixes = [\".mp4\", \".mkv\", \".mov\", \".avi\", \".wmv\", \".flv\", \".webm\", \".3gp\", \".mpeg\"]\n",
        "\n",
        "    print(f\"Processing video file {video_path_local} with ffmpeg..\")\n",
        "\n",
        "    if video_path_local.suffix in valid_suffixes:\n",
        "        input_suffix = video_path_local.suffix\n",
        "        video_path_local = video_path_local.with_suffix(\".wav\")\n",
        "        result = subprocess.run([\"ffmpeg\", \"-i\", str(video_path_local.with_suffix(input_suffix)), \"-vn\", \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", \"-ac\", \"1\", str(video_path_local)])\n"
      ],
      "metadata": {
        "id": "xYLPZQX9S7tU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seconds_to_time_format(s):\n",
        "    # Convert seconds to hours, minutes, seconds, and milliseconds\n",
        "    hours = s // 3600\n",
        "    s %= 3600\n",
        "    minutes = s // 60\n",
        "    s %= 60\n",
        "    seconds = s // 1\n",
        "    milliseconds = round((s % 1) * 1000)\n",
        "\n",
        "    # Return the formatted string\n",
        "    return f\"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{int(milliseconds):03d}\"\n",
        "\n",
        "#@markdown # **Run the model** üöÄ\n",
        "\n",
        "#@markdown Run this cell to execute the transcription/translation of the video. This can take a while and very based on the length of the video and the number of parameters of the model selected above.\n",
        "\n",
        "#@markdown ## **Parameters** ‚öôÔ∏è\n",
        "\n",
        "#@markdown ### **Behavior control**\n",
        "#@markdown #### Language\n",
        "language = \"en\" #@param [\"auto\", \"en\", \"zh\", \"ja\", \"fr\", \"de\"] {allow-input: true}\n",
        "#@markdown #### initial prompt (change to transcribe if you prefer transcribing only)\n",
        "initial_prompt = \"Please translate this from Japanese to English.\" #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Word-level timestamps\n",
        "word_level_timestamps = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown #### VAD filter\n",
        "vad_filter = True #@param {type:\"boolean\"}\n",
        "vad_filter_min_silence_duration_ms = 50 #@param {type:\"integer\"}\n",
        "#@markdown ---\n",
        "#@markdown #### Output (Default is srt, txt if `text_only` be checked )\n",
        "text_only = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "segments, info = model.transcribe(str(video_path_local), beam_size=5,\n",
        "                                  language=None if language == \"auto\" else language,\n",
        "                                  initial_prompt=initial_prompt,\n",
        "                                  word_timestamps=word_level_timestamps,\n",
        "                                  vad_filter=vad_filter,\n",
        "                                  vad_parameters=dict(min_silence_duration_ms=vad_filter_min_silence_duration_ms))\n",
        "\n",
        "display(Markdown(f\"Detected language '{info.language}' with probability {info.language_probability}\"))\n",
        "\n",
        "ext_name = '.txt' if text_only else \".srt\"\n",
        "output_file_name = video_path_local.stem + ext_name\n",
        "sentence_idx = 1\n",
        "with open(output_file_name, 'w') as f:\n",
        "  for segment in segments:\n",
        "    if word_level_timestamps:\n",
        "      for word in segment.words:\n",
        "        ts_start = seconds_to_time_format(word.start)\n",
        "        ts_end = seconds_to_time_format(word.end)\n",
        "        print(f\"[{ts_start} --> {ts_end}] {word.word}\")\n",
        "        if not text_only:\n",
        "          f.write(f\"{sentence_idx}\\n\")\n",
        "          f.write(f\"{ts_start} --> {ts_end}\\n\")\n",
        "          f.write(f\"{word.word}\\n\\n\")\n",
        "        else:\n",
        "          f.write(f\"{word.word}\")\n",
        "        f.write(\"\\n\")\n",
        "        sentence_idx = sentence_idx + 1\n",
        "    else:\n",
        "      ts_start = seconds_to_time_format(segment.start)\n",
        "      ts_end = seconds_to_time_format(segment.end)\n",
        "      print(f\"[{ts_start} --> {ts_end}] {segment.text}\")\n",
        "      if not text_only:\n",
        "        f.write(f\"{sentence_idx}\\n\")\n",
        "        f.write(f\"{ts_start} --> {ts_end}\\n\")\n",
        "        f.write(f\"{segment.text.strip()}\\n\\n\")\n",
        "      else:\n",
        "        f.write(f\"{segment.text.strip()}\\n\")\n",
        "      sentence_idx = sentence_idx + 1\n",
        "\n",
        "try:\n",
        "  files.download(output_file_name)\n",
        "  shutil.copy(video_path_local.parent / output_file_name,\n",
        "            drive_whisper_path / output_file_name\n",
        "  )\n",
        "  display(Markdown(f\"**Output file created: {drive_whisper_path / output_file_name}**\"))\n",
        "except:\n",
        "  display(Markdown(f\"**Output file created: {video_path_local.parent / output_file_name}**\"))\n"
      ],
      "metadata": {
        "id": "Ad6n1m4deAHp",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "name": "faster_whisper youtube/drive.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}