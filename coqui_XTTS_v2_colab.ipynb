{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamed-jamali-software/mp32face/blob/main/coqui_XTTS_v2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "3d10a841-7f1d-4898-9c14-fc9f387393e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'xtts2-hf'...\n",
            "remote: Enumerating objects: 518, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 518 (delta 2), reused 3 (delta 1), pack-reused 512 (from 1)\u001b[K\n",
            "Receiving objects: 100% (518/518), 716.12 KiB | 1.95 MiB/s, done.\n",
            "Resolving deltas: 100% (311/311), done.\n",
            "Downloading examples/female.wav (1.0 MB)\n",
            "Error downloading object: examples/female.wav (89a4fa9): Smudge error: Error downloading examples/female.wav (89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02): [89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02] Object does not exist on the server: [404] Object does not exist on the server\n",
            "\n",
            "Errors logged to /content/xtts2-hf/.git/lfs/logs/20240902T175137.881776329.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: examples/female.wav: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "/content/xtts2-hf\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.3/933.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: 2.0.0: No such file or directory\n",
            "--2024-09-02 17:53:37--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.109.52, 18.238.109.102, 18.238.109.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.109.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Jxv9UsIOO3i3o%7EesbdVqpJuYnvESisXrY11NdjZA7lWBoKlWXJ2zMgj9WxenL0VV5BWZmfJE5-myHR1CkyB07o44KAopJZ7Y7lzblPdH96p7sbH2%7EBJLDhBjNF825KEadd8ONLffxa6rR2riT76kvcfsAh9raUXYRfEXQ5BUxjbsZNYqnvlADYWq31Pe0nGA-Dkwd0OtZOxJ3xFVg10lqGYbKtvcHD7HYon81y4ukRKr51PWjcxlUY9pGcAv6X4nii25lZACscRGaBPGGgbCHA%7ERYNNNBmNC8vAdNihIxJrrnngHj6sQgcueBvoXO3mwws9HG5u%7EmjbRXJH3AMpFzA__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-09-02 17:53:37--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Jxv9UsIOO3i3o%7EesbdVqpJuYnvESisXrY11NdjZA7lWBoKlWXJ2zMgj9WxenL0VV5BWZmfJE5-myHR1CkyB07o44KAopJZ7Y7lzblPdH96p7sbH2%7EBJLDhBjNF825KEadd8ONLffxa6rR2riT76kvcfsAh9raUXYRfEXQ5BUxjbsZNYqnvlADYWq31Pe0nGA-Dkwd0OtZOxJ3xFVg10lqGYbKtvcHD7HYon81y4ukRKr51PWjcxlUY9pGcAv6X4nii25lZACscRGaBPGGgbCHA%7ERYNNNBmNC8vAdNihIxJrrnngHj6sQgcueBvoXO3mwws9HG5u%7EmjbRXJH3AMpFzA__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.206.17, 18.154.206.4, 18.154.206.14, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.206.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002030 (979K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/female.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 978.54K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-09-02 17:53:37 (19.9 MB/s) - ‘/content/xtts2-hf/examples/female.wav’ saved [1002030/1002030]\n",
            "\n",
            "--2024-09-02 17:53:37--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.118, 18.164.174.23, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ITVn-i%7EVqXfzDj-XVGRh1Yfa%7EmAx3gViYhJpRs%7E1bMSHjadDdV6pJUt3MpuZ5MvRADhVnGC99zaO3AON7cdwzbgLxEE1xFCrO7I95auO70%7Ey2petvvg-YVYwOHA1UVwA%7EM822Zy1QgosZZp-jwRRmrsTeD4qdYNx1Ch-zPKTeeKAjqWzlYErIySlB99qmHbRn7VVm6VrIOwuN2hKQm6q-y6YZpxZAb46sXOIl9ZD6IjAIiQW74dRkuR2CUhA8p0D9nInXgK2DnUWLiD-Gq0PKul0qLfKu30R8YCJAYfo3ghHORLPp26OwVkS4JnhrTCnHt5FeA9Mox4qgmiBMe%7E%7EKg__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-09-02 17:53:37--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ITVn-i%7EVqXfzDj-XVGRh1Yfa%7EmAx3gViYhJpRs%7E1bMSHjadDdV6pJUt3MpuZ5MvRADhVnGC99zaO3AON7cdwzbgLxEE1xFCrO7I95auO70%7Ey2petvvg-YVYwOHA1UVwA%7EM822Zy1QgosZZp-jwRRmrsTeD4qdYNx1Ch-zPKTeeKAjqWzlYErIySlB99qmHbRn7VVm6VrIOwuN2hKQm6q-y6YZpxZAb46sXOIl9ZD6IjAIiQW74dRkuR2CUhA8p0D9nInXgK2DnUWLiD-Gq0PKul0qLfKu30R8YCJAYfo3ghHORLPp26OwVkS4JnhrTCnHt5FeA9Mox4qgmiBMe%7E%7EKg__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.206.4, 18.154.206.14, 18.154.206.17, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.206.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 762126 (744K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/male.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 744.26K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-09-02 17:53:37 (20.4 MB/s) - ‘/content/xtts2-hf/examples/male.wav’ saved [762126/762126]\n",
            "\n",
            "--2024-09-02 17:53:37--  https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.23, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725558818&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=c0qbXGRoWkiEW0hZ4wWWLoPNhbqz0w5-a8SAAPh1zM2pZZ8iSb11Vfmbqo%7EV-Cvuup8iv--1Oar-ptnZGghvrLg3oFWpEX%7EYWjgW1s67BPDTA%7E0zcpw6809tCokqPaSrkJ7Iea19olRK7GHkwCMY60cJbJxvIvrTFgRS6Tvl78vIkxgtj777rnLJcpCR7fzh3RBdlVJMxbYiaUsV2jOZ9Pkf9zhB51Jkk65WXqJf2L7UT%7EsbBWUYl-l8zlh2XrNDoCqqTmaAuOSDWUG70cTH4aKw%7ENlEJjowweSDlCjgmpgQGXTSCwTS6ldJ%7EFVNQ44q8WfeYIyh%7Enr54-wsOYTJlQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-09-02 17:53:38--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725558818&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=c0qbXGRoWkiEW0hZ4wWWLoPNhbqz0w5-a8SAAPh1zM2pZZ8iSb11Vfmbqo%7EV-Cvuup8iv--1Oar-ptnZGghvrLg3oFWpEX%7EYWjgW1s67BPDTA%7E0zcpw6809tCokqPaSrkJ7Iea19olRK7GHkwCMY60cJbJxvIvrTFgRS6Tvl78vIkxgtj777rnLJcpCR7fzh3RBdlVJMxbYiaUsV2jOZ9Pkf9zhB51Jkk65WXqJf2L7UT%7EsbBWUYl-l8zlh2XrNDoCqqTmaAuOSDWUG70cTH4aKw%7ENlEJjowweSDlCjgmpgQGXTSCwTS6ldJ%7EFVNQ44q8WfeYIyh%7Enr54-wsOYTJlQ__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.206.14, 18.154.206.28, 18.154.206.17, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.206.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29207056 (28M) [application/zip]\n",
            "Saving to: ‘/content/xtts2-hf/ffmpeg.zip’\n",
            "\n",
            "/content/xtts2-hf/f 100%[===================>]  27.85M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-02 17:53:38 (238 MB/s) - ‘/content/xtts2-hf/ffmpeg.zip’ saved [29207056/29207056]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/xtts2-hf\n",
        "%cd /content/xtts2-hf\n",
        "!pip install -q gradio==3.50.2 TTS==0.21.1 langid unidic-lite unidic deepspeed\n",
        "!pip install -q numpy<2.0.0 -U\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav -O /content/xtts2-hf/examples/female.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav -O /content/xtts2-hf/examples/male.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip -O /content/xtts2-hf/ffmpeg.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io, os, stat\n",
        "import subprocess\n",
        "import random\n",
        "from zipfile import ZipFile\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import langid\n",
        "import re\n",
        "from zipfile import ZipFile\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "from huggingface_hub import HfApi\n"
      ],
      "metadata": {
        "id": "FBIbnUWp3xnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.system('python -m unidic download')\n",
        "\n",
        "# By using XTTS you agree to CPML license https://coqui.ai/cpml\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "api = HfApi(token=HF_TOKEN)\n",
        "repo_id = \"coqui/xtts\"\n",
        "\n",
        "# Use newer ffmpeg binary for Ubuntu20 to use denoising for microphone input\n",
        "print(\"Export newer ffmpeg binary for denoise filter\")\n",
        "ZipFile(\"ffmpeg.zip\").extractall()\n",
        "print(\"Make ffmpeg binary executable\")\n",
        "st = os.stat(\"ffmpeg\")\n",
        "os.chmod(\"ffmpeg\", st.st_mode | stat.S_IEXEC)\n",
        "\n",
        "# This will trigger downloading model\n",
        "print(\"Downloading if not downloaded Coqui XTTS V2\")\n",
        "from TTS.utils.manage import ModelManager\n",
        "\n",
        "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "ModelManager().download_model(model_name)\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), model_name.replace(\"/\", \"--\"))\n",
        "print(\"XTTS downloaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ioRt7sJoNU",
        "outputId": "5790578b-a959-4738-dbc8-d525c14733bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export newer ffmpeg binary for denoise filter\n",
            "Make ffmpeg binary executable\n",
            "Downloading if not downloaded Coqui XTTS V2\n",
            " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n",
            " > Model's license - CPML\n",
            " > Check https://coqui.ai/cpml.txt for more info.\n",
            "XTTS downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True,\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "DEVICE_ASSERT_DETECTED = 0\n",
        "DEVICE_ASSERT_PROMPT = None\n",
        "DEVICE_ASSERT_LANG = None\n",
        "\n",
        "supported_languages = config.languages\n"
      ],
      "metadata": {
        "id": "6HyR4IDBJqjL",
        "outputId": "9a01d26a-6411-42bf-9003-22a9341b4744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-09-02 17:55:37,643] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-09-02 17:55:39,794] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-09-02 17:55:39,796] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
            "[2024-09-02 17:55:39,799] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
            "[2024-09-02 17:55:39,801] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/transformer_inference...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/transformer_inference/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module transformer_inference...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load transformer_inference op: 82.68424773216248 seconds\n",
            "[2024-09-02 17:57:03,228] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module transformer_inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import re\n",
        "import datetime\n",
        "import csv\n",
        "from io import StringIO\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "ad278dN2TzT-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, max_length=133):\n",
        "    return textwrap.wrap(text, width=max_length, break_long_words=False)\n"
      ],
      "metadata": {
        "id": "AhUhgkQOT5LU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_silence(duration_seconds, file_path, sample_rate=24000):\n",
        "    # تعداد نمونه‌ها به ازای مدت زمان\n",
        "    num_samples = int(duration_seconds * sample_rate)\n",
        "    # ایجاد آرایه‌ای از صفرها (صداهای خالی)\n",
        "    silence = np.zeros(num_samples, dtype=np.float32)\n",
        "    # ذخیره فایل WAV\n",
        "    torchaudio.save(file_path, torch.tensor([silence]), sample_rate)"
      ],
      "metadata": {
        "id": "j2vhMRui43GD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(prompt, language, audio_file_pth=None, mic_file_path=None, use_mic=False, voice_cleanup=False, no_lang_auto_detect=False, agree=True, output_file=None):\n",
        "    if agree:\n",
        "\n",
        "\n",
        "        speaker_wav = audio_file_pth\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            prompt = re.sub(\"([^\\x00-\\x7F]|\\w)(\\.|\\。|\\?)\", r\"\\1 \\2\\2\", prompt)\n",
        "            print(\"Generating new audio...\")\n",
        "            # t0 = time.time() # زمان شروع فرآیند تولید صوت\n",
        "            out = model.inference(\n",
        "                prompt,\n",
        "                language,\n",
        "                *model.get_conditioning_latents(audio_path=speaker_wav, gpt_cond_len=30, gpt_cond_chunk_len=4, max_ref_length=60),\n",
        "                repetition_penalty=5.0,\n",
        "                temperature=0.75,\n",
        "            )\n",
        "            # inference_time = time.time() - t0\n",
        "            # print(f\"Time to generate audio: {round(inference_time * 1000)} milliseconds\")\n",
        "            # real_time_factor = (time.time() - t0) / out['wav'].shape[-1] * 24000\n",
        "            # print(f\"Real-time factor (RTF): {real_time_factor}\")\n",
        "            torchaudio.save(output_file, torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "            print(\"Audio saved to  \"+output_file + \"  sentence : \" + prompt)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"device-side assert\" in str(e):\n",
        "                print(f\"Exit due to: Unrecoverable exception caused by language:{language} prompt:{prompt}\")\n",
        "                print(\"Unhandled Exception encounter, please retry in a minute\")\n",
        "                print(\"Cuda device-assert Runtime encountered need restart\")\n",
        "                if not DEVICE_ASSERT_DETECTED:\n",
        "                    DEVICE_ASSERT_DETECTED = 1\n",
        "                    DEVICE_ASSERT_PROMPT = prompt\n",
        "                    DEVICE_ASSERT_LANG = language\n",
        "\n",
        "                error_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "                error_data = [\n",
        "                    error_time,\n",
        "                    prompt,\n",
        "                    language,\n",
        "                    audio_file_pth,\n",
        "                    mic_file_path,\n",
        "                    use_mic,\n",
        "                    voice_cleanup,\n",
        "                    no_lang_auto_detect,\n",
        "                    agree,\n",
        "                ]\n",
        "                error_data = [str(e) if type(e) != str else e for e in error_data]\n",
        "                print(error_data)\n",
        "                write_io = StringIO()\n",
        "                csv.writer(write_io).writerows([error_data])\n",
        "                csv_upload = write_io.getvalue().encode()\n",
        "\n",
        "                filename = error_time + \"_\" + str(uuid.uuid4()) + \".csv\"\n",
        "                print(\"Writing error csv\")\n",
        "                error_api = HfApi()\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=csv_upload,\n",
        "                    path_in_repo=filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                print(\"Writing error reference audio\")\n",
        "                speaker_filename = error_time + \"_reference_\" + str(uuid.uuid4()) + \".wav\"\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=speaker_wav,\n",
        "                    path_in_repo=speaker_filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                space = api.get_space_runtime(repo_id=repo_id)\n",
        "                if space.stage != \"BUILDING\":\n",
        "                    api.restart_space(repo_id=repo_id)\n",
        "                else:\n",
        "                    print(\"TRIED TO RESTART but space is building\")\n",
        "            else:\n",
        "                if \"Failed to decode\" in str(e):\n",
        "                    print(\"Speaker encoding error\", str(e))\n",
        "                else:\n",
        "                    print(\"RuntimeError: non device-side assert error:\", str(e))\n",
        "                return None\n",
        "\n",
        "        return output_file\n"
      ],
      "metadata": {
        "id": "G-w6GgCEUGRW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_speech(prompt, language_code, chunk_id):\n",
        "    output_file = f\"chunk_{chunk_id}.wav\"\n",
        "    language_code = \"en\"\n",
        "    audio_file_path = '/content/5.mp3'  # Path to reference audio file if needed\n",
        "    mic_file_path = None  # Path to microphone recorded audio if needed\n",
        "    use_microphone = False\n",
        "    voice_cleanup = True\n",
        "    disable_lang_auto_detect = True\n",
        "\n",
        "\n",
        "    speaker_wav = audio_file_path\n",
        "\n",
        "    # Filtering for microphone input\n",
        "    lowpassfilter = denoise = trim = loudness = True\n",
        "    lowpass_highpass = \"lowpass=8000,highpass=75,\" if lowpassfilter else \"\"\n",
        "    trim_silence = \"areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,\" if trim else \"\"\n",
        "\n",
        "    out_filename = speaker_wav + \"filter.wav\"\n",
        "    shell_command = f\"./ffmpeg -y -i {speaker_wav} -af {lowpass_highpass}{trim_silence} {out_filename}\".split(\" \")\n",
        "    subprocess.run(shell_command, capture_output=False, text=True, check=True)\n",
        "    speaker_wav = out_filename\n",
        "\n",
        "    return text_to_speech(\n",
        "        prompt=prompt,\n",
        "        language=language_code,\n",
        "        audio_file_pth=speaker_wav,\n",
        "        mic_file_path=mic_file_path,\n",
        "        use_mic=use_microphone,\n",
        "        voice_cleanup=voice_cleanup,\n",
        "        no_lang_auto_detect=disable_lang_auto_detect,\n",
        "        agree=True,\n",
        "        output_file= output_file)"
      ],
      "metadata": {
        "id": "hOL9GLg4YSmh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to combine multiple audio files into one\n",
        "def combine_audio_files(audio_files, output_file):\n",
        "\n",
        "    with open(\"file_list.txt\", \"w\") as file_list:\n",
        "      for audio_file in audio_files:\n",
        "          file_list.write(f\"file '{audio_file}'\\n\")\n",
        "\n",
        "    command = [\"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"file_list.txt\", \"-c\", \"copy\", output_file]\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        print(f\"Audio files successfully combined into {output_file}\")\n",
        "        print(result.stdout)\n",
        "        print(result.stderr)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error occurred during combining audio files: {e}\")\n",
        "        print(e.stdout)\n",
        "        print(e.stderr)\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "      os.remove(audio_file)\n",
        "\n",
        "    # with open(output_file, 'wb') as outfile:\n",
        "    #     for audio_file in audio_files:\n",
        "    #         with open(audio_file, 'rb') as infile:\n",
        "    #             outfile.write(infile.read())\n",
        "            # Clean up temporary files\n",
        "            # os.remove(audio_file)"
      ],
      "metadata": {
        "id": "FFhNU1zhXu52"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_to_speech(text, language_code):\n",
        "    # Split text into chunks of 200 characters\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    sentences = re.split(r'(?<=[.!?]|\\[|\\])\\s+', text)\n",
        "\n",
        "    all_audio_files = []\n",
        "\n",
        "\n",
        "    if os.path.isfile(\"combined_output.wav\"):\n",
        "      os.remove(\"combined_output.wav\")\n",
        "\n",
        "    total_sentences = len(sentences)\n",
        "    for idx, sentence in enumerate(sentences):\n",
        "        print(f\"Processing sentence {idx + 1} of {total_sentences}...\")\n",
        "        temp_file = generate_speech(sentence, language_code, idx + 1)\n",
        "        if os.path.exists(temp_file):\n",
        "            all_audio_files.append(temp_file)\n",
        "\n",
        "            # ایجاد فایل صوتی خالی با مدت زمان رندوم\n",
        "            silence_duration = random.uniform(1, 2)  # مدت زمان رندوم بین 1 تا 2 ثانیه\n",
        "            silence_file = f\"silence_{idx + 1}.wav\"\n",
        "            create_silence(silence_duration, silence_file)\n",
        "            all_audio_files.append(silence_file)\n",
        "        else:\n",
        "            print(f\"Failed to generate audio for sentence {idx + 1}.\")\n",
        "\n",
        "    # Combine all audio files into one\n",
        "    if all_audio_files:\n",
        "        combined_audio = \"combined_output.wav\"\n",
        "        combine_audio_files(all_audio_files, combined_audio)\n",
        "        print(f\"All audio files combined into {combined_audio}\")\n",
        "\n",
        "        files.download(\"combined_output.wav\")\n",
        "\n",
        "    else:\n",
        "        print(\"No audio files to combine.\")"
      ],
      "metadata": {
        "id": "qn9SMN3uUVWN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "prompt_text = \"\"\"\n",
        "\n",
        "Hello and welcome to hamjam.\n",
        "\n",
        "I’m hamjam, and in today’s video, we’re going to explore [how to get motivated, stay disciplined, be productive and ultimately re-invent yourself on your self-improvement journey].\n",
        "\n",
        "If you’re passionate about living a well-ordered life and achieving financial success, you’re in the right place! Be sure to hit that like button if you enjoy the content, and don’t forget to subscribe to stay updated with all our latest videos.\n",
        "\n",
        "Let’s dive in and start transforming your life together!\n",
        "\n",
        "\n",
        "The greatest achievements often come right after our worst defeats. It's time to get back to work and stop listening to your own excuses. Get off the podcasts, step away from social media, and silence the noise around you. You need to return to your mental lab. This work is not just an apology to yourself; it’s an apology for wasting time, for holding yourself back, and for sabotaging your own success.\n",
        "\n",
        "If you're reading this, it's clear that you're sick and tired of being sick and tired. You've had enough of being average. There comes a point when being mediocre becomes nauseating, when it makes you want to throw up. If you don’t feel this way, maybe this message isn’t for you. But if you do, it’s time for version 2.0 of yourself to emerge—the version that is committed to your goals no matter what, that feels the fear but does it anyway, and that attacks your goals relentlessly without procrastination.\n",
        "\n",
        "I’m in this phase too. For too long, I was stuck in a rut, putting off achieving the goals I set for myself. Instead of doing the work that would move my life forward, I indulged in activities that were no good for me—this is called escapism. I avoided chasing my goals because I was afraid of being laughed at. I talked a lot about achieving big things, but I never took action. I couldn't focus on any task because I was constantly distracted. As soon as I felt any resistance, I would seek out cheap dopamine. But eventually, something snapped. I realized that enough is enough. How much longer are we going to spend debating our goals before we actually get up and do something? Ask yourself: what would be worse—the pain of getting to the end of your life and realizing you lived in regret, or the pain of enduring a hard task that would give you a sense of accomplishment? You know the answer.\n",
        "\n",
        "So let me tell you how we’re going to make the greatest comeback of our lives and evolve into the best version of ourselves. It's time for 2.0. You’ve got to disappear for a few months and focus on self-improvement. I don’t mean in some emo, antisocial way, but in a focused, goal-oriented manner. What you have now is not a dream because you will make it a reality.\n",
        "\n",
        "Let’s quickly summarize using an example like Sasuke. He spent his entire youth training and seeking power to become stronger and avenge his clan. He had a single-minded focus on his goal. We need to apply this same mindset to our own lives. Attack your goals with unwavering confidence. Don’t waste time sitting around debating your goals; you need to build momentum, and success will follow. This momentum comes from an attacking mindset.\n",
        "\n",
        "Over the next few months, you need to improve every aspect of your life. The best place to start is by establishing a powerful routine. It might sound cliché, but once you create a strong routine, you’ll realize just how powerful it can be. When you set an early wake-up time and tackle the hardest task of the day first thing in the morning, it breeds confidence. The saying goes, \"If you win the morning, you win the day,\" and if you keep winning days, you win the weeks, months, and eventually the year. The momentum from the morning carries through the day, and when you consistently do what you say you will do, it breeds confidence.\n",
        "\n",
        "Personally, I wake up at 6 a.m., start my day with an ice bath and a workout. This sets the tone for the day, giving me the confidence to attack the rest of my goals. For too long, I unknowingly lived resenting myself for being unproductive and lazy, but that’s no longer the case. Just following a morning routine like Huberman's is the best choice. Start your day with something challenging, and build from there. If you win the morning, the rest of the day falls into place.\n",
        "\n",
        "During this comeback, you must be disciplined. You have to consistently follow through on your tasks and build a ferocious mindset. Believe in yourself and your abilities. Over time, this discipline will turn into a habit, allowing you to live with greater confidence.\n",
        "\n",
        "To sum it up, you have to improve your physique by going to the gym consistently, upgrade your knowledge by reading books and listening to informative podcasts, and most importantly, evolve your mindset. Why walk through life thinking you're anything less than capable? The alternative is simply not acceptable. Look at the best athletes and successful people you admire; they have built a mindset of ferocity and belief in themselves, no matter what. You can do the same. Use the pain you’ve experienced as fuel to succeed, and remember: this is your comeback.\n",
        "\n",
        "\n",
        "I hope you found today’s video helpful and inspiring. If you enjoyed it, please give us a thumbs up and share it with anyone who might benefit from it.\n",
        "\n",
        "Remember to subscribe if you haven’t already, so you never miss out on our latest tips and insights. Feel free to leave a comment below with your thoughts or any questions you have — I love hearing from you!\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "process_text_to_speech(prompt_text, language_code=\"en\")"
      ],
      "metadata": {
        "id": "3ZUz9btqUaVX",
        "outputId": "a9c5a5cc-ef07-4217-f319-32d9a11b669c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sentence 1 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_1.wav  sentence : \n",
            "\n",
            "Hello and welcome to hamjam ..\n",
            "Processing sentence 2 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_2.wav  sentence : I’m hamjam, and in today’s video, we’re going to explore [how to get motivated, stay disciplined, be productive and ultimately re-invent yourself on your self-improvement journey].\n",
            "Processing sentence 3 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_3.wav  sentence : If you’re passionate about living a well-ordered life and achieving financial success, you’re in the right place!\n",
            "Processing sentence 4 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_4.wav  sentence : Be sure to hit that like button if you enjoy the content, and don’t forget to subscribe to stay updated with all our latest videos ..\n",
            "Processing sentence 5 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_5.wav  sentence : Let’s dive in and start transforming your life together!\n",
            "Processing sentence 6 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_6.wav  sentence : The greatest achievements often come right after our worst defeats ..\n",
            "Processing sentence 7 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_7.wav  sentence : It's time to get back to work and stop listening to your own excuses ..\n",
            "Processing sentence 8 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_8.wav  sentence : Get off the podcasts, step away from social media, and silence the noise around you ..\n",
            "Processing sentence 9 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_9.wav  sentence : You need to return to your mental lab ..\n",
            "Processing sentence 10 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_10.wav  sentence : This work is not just an apology to yourself; it’s an apology for wasting time, for holding yourself back, and for sabotaging your own success ..\n",
            "Processing sentence 11 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_11.wav  sentence : If you're reading this, it's clear that you're sick and tired of being sick and tired ..\n",
            "Processing sentence 12 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_12.wav  sentence : You've had enough of being average ..\n",
            "Processing sentence 13 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_13.wav  sentence : There comes a point when being mediocre becomes nauseating, when it makes you want to throw up ..\n",
            "Processing sentence 14 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_14.wav  sentence : If you don’t feel this way, maybe this message isn’t for you ..\n",
            "Processing sentence 15 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_15.wav  sentence : But if you do, it’s time for version 2 ..0 of yourself to emerge—the version that is committed to your goals no matter what, that feels the fear but does it anyway, and that attacks your goals relentlessly without procrastination ..\n",
            "Processing sentence 16 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_16.wav  sentence : I’m in this phase too ..\n",
            "Processing sentence 17 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_17.wav  sentence : For too long, I was stuck in a rut, putting off achieving the goals I set for myself ..\n",
            "Processing sentence 18 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_18.wav  sentence : Instead of doing the work that would move my life forward, I indulged in activities that were no good for me—this is called escapism ..\n",
            "Processing sentence 19 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_19.wav  sentence : I avoided chasing my goals because I was afraid of being laughed at ..\n",
            "Processing sentence 20 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_20.wav  sentence : I talked a lot about achieving big things, but I never took action ..\n",
            "Processing sentence 21 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_21.wav  sentence : I couldn't focus on any task because I was constantly distracted ..\n",
            "Processing sentence 22 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_22.wav  sentence : As soon as I felt any resistance, I would seek out cheap dopamine ..\n",
            "Processing sentence 23 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_23.wav  sentence : But eventually, something snapped ..\n",
            "Processing sentence 24 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_24.wav  sentence : I realized that enough is enough ..\n",
            "Processing sentence 25 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_25.wav  sentence : How much longer are we going to spend debating our goals before we actually get up and do something ??\n",
            "Processing sentence 26 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_26.wav  sentence : Ask yourself: what would be worse—the pain of getting to the end of your life and realizing you lived in regret, or the pain of enduring a hard task that would give you a sense of accomplishment ??\n",
            "Processing sentence 27 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_27.wav  sentence : You know the answer ..\n",
            "Processing sentence 28 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_28.wav  sentence : So let me tell you how we’re going to make the greatest comeback of our lives and evolve into the best version of ourselves ..\n",
            "Processing sentence 29 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_29.wav  sentence : It's time for 2 ..0 ..\n",
            "Processing sentence 30 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_30.wav  sentence : You’ve got to disappear for a few months and focus on self-improvement ..\n",
            "Processing sentence 31 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_31.wav  sentence : I don’t mean in some emo, antisocial way, but in a focused, goal-oriented manner ..\n",
            "Processing sentence 32 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_32.wav  sentence : What you have now is not a dream because you will make it a reality ..\n",
            "Processing sentence 33 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_33.wav  sentence : Let’s quickly summarize using an example like Sasuke ..\n",
            "Processing sentence 34 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_34.wav  sentence : He spent his entire youth training and seeking power to become stronger and avenge his clan ..\n",
            "Processing sentence 35 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_35.wav  sentence : He had a single-minded focus on his goal ..\n",
            "Processing sentence 36 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_36.wav  sentence : We need to apply this same mindset to our own lives ..\n",
            "Processing sentence 37 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_37.wav  sentence : Attack your goals with unwavering confidence ..\n",
            "Processing sentence 38 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_38.wav  sentence : Don’t waste time sitting around debating your goals; you need to build momentum, and success will follow ..\n",
            "Processing sentence 39 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_39.wav  sentence : This momentum comes from an attacking mindset ..\n",
            "Processing sentence 40 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_40.wav  sentence : Over the next few months, you need to improve every aspect of your life ..\n",
            "Processing sentence 41 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_41.wav  sentence : The best place to start is by establishing a powerful routine ..\n",
            "Processing sentence 42 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_42.wav  sentence : It might sound cliché, but once you create a strong routine, you’ll realize just how powerful it can be ..\n",
            "Processing sentence 43 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_43.wav  sentence : When you set an early wake-up time and tackle the hardest task of the day first thing in the morning, it breeds confidence ..\n",
            "Processing sentence 44 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_44.wav  sentence : The saying goes, \"If you win the morning, you win the day,\" and if you keep winning days, you win the weeks, months, and eventually the year ..\n",
            "Processing sentence 45 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_45.wav  sentence : The momentum from the morning carries through the day, and when you consistently do what you say you will do, it breeds confidence ..\n",
            "Processing sentence 46 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_46.wav  sentence : Personally, I wake up at 6 a ..m .., start my day with an ice bath and a workout ..\n",
            "Processing sentence 47 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_47.wav  sentence : This sets the tone for the day, giving me the confidence to attack the rest of my goals ..\n",
            "Processing sentence 48 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_48.wav  sentence : For too long, I unknowingly lived resenting myself for being unproductive and lazy, but that’s no longer the case ..\n",
            "Processing sentence 49 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_49.wav  sentence : Just following a morning routine like Huberman's is the best choice ..\n",
            "Processing sentence 50 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_50.wav  sentence : Start your day with something challenging, and build from there ..\n",
            "Processing sentence 51 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_51.wav  sentence : If you win the morning, the rest of the day falls into place ..\n",
            "Processing sentence 52 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_52.wav  sentence : During this comeback, you must be disciplined ..\n",
            "Processing sentence 53 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_53.wav  sentence : You have to consistently follow through on your tasks and build a ferocious mindset ..\n",
            "Processing sentence 54 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_54.wav  sentence : Believe in yourself and your abilities ..\n",
            "Processing sentence 55 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_55.wav  sentence : Over time, this discipline will turn into a habit, allowing you to live with greater confidence ..\n",
            "Processing sentence 56 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_56.wav  sentence : To sum it up, you have to improve your physique by going to the gym consistently, upgrade your knowledge by reading books and listening to informative podcasts, and most importantly, evolve your mindset ..\n",
            "Processing sentence 57 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_57.wav  sentence : Why walk through life thinking you're anything less than capable ??\n",
            "Processing sentence 58 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_58.wav  sentence : The alternative is simply not acceptable ..\n",
            "Processing sentence 59 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_59.wav  sentence : Look at the best athletes and successful people you admire; they have built a mindset of ferocity and belief in themselves, no matter what ..\n",
            "Processing sentence 60 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_60.wav  sentence : You can do the same ..\n",
            "Processing sentence 61 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_61.wav  sentence : Use the pain you’ve experienced as fuel to succeed, and remember: this is your comeback ..\n",
            "Processing sentence 62 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_62.wav  sentence : I hope you found today’s video helpful and inspiring ..\n",
            "Processing sentence 63 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_63.wav  sentence : If you enjoyed it, please give us a thumbs up and share it with anyone who might benefit from it ..\n",
            "Processing sentence 64 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_64.wav  sentence : Remember to subscribe if you haven’t already, so you never miss out on our latest tips and insights ..\n",
            "Processing sentence 65 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_65.wav  sentence : Feel free to leave a comment below with your thoughts or any questions you have — I love hearing from you!\n",
            "Processing sentence 66 of 66...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_66.wav  sentence : \n",
            "Audio files successfully combined into combined_output.wav\n",
            "\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, concat, from 'file_list.txt':\n",
            "  Duration: N/A, start: 0.000000, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Output #0, wav, to 'combined_output.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "size=       4kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
            "size=    6656kB time=00:02:22.54 bitrate= 382.5kbits/s speed= 284x    \n",
            "size=   13824kB time=00:04:55.63 bitrate= 383.1kbits/s speed= 293x    \n",
            "size=   17920kB time=00:06:25.70 bitrate= 380.6kbits/s speed= 255x    \n",
            "size=   22362kB time=00:07:57.04 bitrate= 384.0kbits/s speed= 281x    \n",
            "video:0kB audio:22362kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000341%\n",
            "\n",
            "All audio files combined into combined_output.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = [\n",
        "    \"ffmpeg\",\n",
        "    \"-y\",\n",
        "    \"-i\", \"combined_output.wav\",\n",
        "    \"-filter:a\", \"atempo=0.93\",\n",
        "    \"output_final.wav\"\n",
        "]\n",
        "\n",
        "\n",
        "# اجرای فرمان FFmpeg\n",
        "try:\n",
        "    result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    print(\"Command executed successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"Error occurred:\")\n",
        "    print(e.stderr)"
      ],
      "metadata": {
        "id": "Crue82UIiweh",
        "outputId": "8eb4bf11-563e-4f84-f24e-93fd4f06276d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command executed successfully.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}