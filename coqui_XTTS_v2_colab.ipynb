{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamed-jamali-software/mp32face/blob/main/coqui_XTTS_v2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "3d10a841-7f1d-4898-9c14-fc9f387393e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'xtts2-hf'...\n",
            "remote: Enumerating objects: 518, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 518 (delta 2), reused 3 (delta 1), pack-reused 512 (from 1)\u001b[K\n",
            "Receiving objects: 100% (518/518), 716.12 KiB | 1.95 MiB/s, done.\n",
            "Resolving deltas: 100% (311/311), done.\n",
            "Downloading examples/female.wav (1.0 MB)\n",
            "Error downloading object: examples/female.wav (89a4fa9): Smudge error: Error downloading examples/female.wav (89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02): [89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02] Object does not exist on the server: [404] Object does not exist on the server\n",
            "\n",
            "Errors logged to /content/xtts2-hf/.git/lfs/logs/20240902T175137.881776329.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: examples/female.wav: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "/content/xtts2-hf\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.3/933.3 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: 2.0.0: No such file or directory\n",
            "--2024-09-02 17:53:37--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.109.52, 18.238.109.102, 18.238.109.121, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.109.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Jxv9UsIOO3i3o%7EesbdVqpJuYnvESisXrY11NdjZA7lWBoKlWXJ2zMgj9WxenL0VV5BWZmfJE5-myHR1CkyB07o44KAopJZ7Y7lzblPdH96p7sbH2%7EBJLDhBjNF825KEadd8ONLffxa6rR2riT76kvcfsAh9raUXYRfEXQ5BUxjbsZNYqnvlADYWq31Pe0nGA-Dkwd0OtZOxJ3xFVg10lqGYbKtvcHD7HYon81y4ukRKr51PWjcxlUY9pGcAv6X4nii25lZACscRGaBPGGgbCHA%7ERYNNNBmNC8vAdNihIxJrrnngHj6sQgcueBvoXO3mwws9HG5u%7EmjbRXJH3AMpFzA__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-09-02 17:53:37--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Jxv9UsIOO3i3o%7EesbdVqpJuYnvESisXrY11NdjZA7lWBoKlWXJ2zMgj9WxenL0VV5BWZmfJE5-myHR1CkyB07o44KAopJZ7Y7lzblPdH96p7sbH2%7EBJLDhBjNF825KEadd8ONLffxa6rR2riT76kvcfsAh9raUXYRfEXQ5BUxjbsZNYqnvlADYWq31Pe0nGA-Dkwd0OtZOxJ3xFVg10lqGYbKtvcHD7HYon81y4ukRKr51PWjcxlUY9pGcAv6X4nii25lZACscRGaBPGGgbCHA%7ERYNNNBmNC8vAdNihIxJrrnngHj6sQgcueBvoXO3mwws9HG5u%7EmjbRXJH3AMpFzA__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.206.17, 18.154.206.4, 18.154.206.14, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.206.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002030 (979K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/female.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 978.54K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-09-02 17:53:37 (19.9 MB/s) - ‘/content/xtts2-hf/examples/female.wav’ saved [1002030/1002030]\n",
            "\n",
            "--2024-09-02 17:53:37--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.118, 18.164.174.23, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ITVn-i%7EVqXfzDj-XVGRh1Yfa%7EmAx3gViYhJpRs%7E1bMSHjadDdV6pJUt3MpuZ5MvRADhVnGC99zaO3AON7cdwzbgLxEE1xFCrO7I95auO70%7Ey2petvvg-YVYwOHA1UVwA%7EM822Zy1QgosZZp-jwRRmrsTeD4qdYNx1Ch-zPKTeeKAjqWzlYErIySlB99qmHbRn7VVm6VrIOwuN2hKQm6q-y6YZpxZAb46sXOIl9ZD6IjAIiQW74dRkuR2CUhA8p0D9nInXgK2DnUWLiD-Gq0PKul0qLfKu30R8YCJAYfo3ghHORLPp26OwVkS4JnhrTCnHt5FeA9Mox4qgmiBMe%7E%7EKg__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-09-02 17:53:37--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725558817&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ITVn-i%7EVqXfzDj-XVGRh1Yfa%7EmAx3gViYhJpRs%7E1bMSHjadDdV6pJUt3MpuZ5MvRADhVnGC99zaO3AON7cdwzbgLxEE1xFCrO7I95auO70%7Ey2petvvg-YVYwOHA1UVwA%7EM822Zy1QgosZZp-jwRRmrsTeD4qdYNx1Ch-zPKTeeKAjqWzlYErIySlB99qmHbRn7VVm6VrIOwuN2hKQm6q-y6YZpxZAb46sXOIl9ZD6IjAIiQW74dRkuR2CUhA8p0D9nInXgK2DnUWLiD-Gq0PKul0qLfKu30R8YCJAYfo3ghHORLPp26OwVkS4JnhrTCnHt5FeA9Mox4qgmiBMe%7E%7EKg__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.206.4, 18.154.206.14, 18.154.206.17, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.206.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 762126 (744K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/male.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 744.26K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-09-02 17:53:37 (20.4 MB/s) - ‘/content/xtts2-hf/examples/male.wav’ saved [762126/762126]\n",
            "\n",
            "--2024-09-02 17:53:37--  https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.55, 18.164.174.23, 18.164.174.17, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725558818&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=c0qbXGRoWkiEW0hZ4wWWLoPNhbqz0w5-a8SAAPh1zM2pZZ8iSb11Vfmbqo%7EV-Cvuup8iv--1Oar-ptnZGghvrLg3oFWpEX%7EYWjgW1s67BPDTA%7E0zcpw6809tCokqPaSrkJ7Iea19olRK7GHkwCMY60cJbJxvIvrTFgRS6Tvl78vIkxgtj777rnLJcpCR7fzh3RBdlVJMxbYiaUsV2jOZ9Pkf9zhB51Jkk65WXqJf2L7UT%7EsbBWUYl-l8zlh2XrNDoCqqTmaAuOSDWUG70cTH4aKw%7ENlEJjowweSDlCjgmpgQGXTSCwTS6ldJ%7EFVNQ44q8WfeYIyh%7Enr54-wsOYTJlQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-09-02 17:53:38--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725558818&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTU1ODgxOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=c0qbXGRoWkiEW0hZ4wWWLoPNhbqz0w5-a8SAAPh1zM2pZZ8iSb11Vfmbqo%7EV-Cvuup8iv--1Oar-ptnZGghvrLg3oFWpEX%7EYWjgW1s67BPDTA%7E0zcpw6809tCokqPaSrkJ7Iea19olRK7GHkwCMY60cJbJxvIvrTFgRS6Tvl78vIkxgtj777rnLJcpCR7fzh3RBdlVJMxbYiaUsV2jOZ9Pkf9zhB51Jkk65WXqJf2L7UT%7EsbBWUYl-l8zlh2XrNDoCqqTmaAuOSDWUG70cTH4aKw%7ENlEJjowweSDlCjgmpgQGXTSCwTS6ldJ%7EFVNQ44q8WfeYIyh%7Enr54-wsOYTJlQ__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.206.14, 18.154.206.28, 18.154.206.17, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.206.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29207056 (28M) [application/zip]\n",
            "Saving to: ‘/content/xtts2-hf/ffmpeg.zip’\n",
            "\n",
            "/content/xtts2-hf/f 100%[===================>]  27.85M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-02 17:53:38 (238 MB/s) - ‘/content/xtts2-hf/ffmpeg.zip’ saved [29207056/29207056]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/xtts2-hf\n",
        "%cd /content/xtts2-hf\n",
        "!pip install -q gradio==3.50.2 TTS==0.21.1 langid unidic-lite unidic deepspeed\n",
        "!pip install -q numpy<2.0.0 -U\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav -O /content/xtts2-hf/examples/female.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav -O /content/xtts2-hf/examples/male.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip -O /content/xtts2-hf/ffmpeg.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io, os, stat\n",
        "import subprocess\n",
        "import random\n",
        "from zipfile import ZipFile\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import langid\n",
        "import re\n",
        "from zipfile import ZipFile\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "from huggingface_hub import HfApi\n"
      ],
      "metadata": {
        "id": "FBIbnUWp3xnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.system('python -m unidic download')\n",
        "\n",
        "# By using XTTS you agree to CPML license https://coqui.ai/cpml\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "api = HfApi(token=HF_TOKEN)\n",
        "repo_id = \"coqui/xtts\"\n",
        "\n",
        "# Use newer ffmpeg binary for Ubuntu20 to use denoising for microphone input\n",
        "print(\"Export newer ffmpeg binary for denoise filter\")\n",
        "ZipFile(\"ffmpeg.zip\").extractall()\n",
        "print(\"Make ffmpeg binary executable\")\n",
        "st = os.stat(\"ffmpeg\")\n",
        "os.chmod(\"ffmpeg\", st.st_mode | stat.S_IEXEC)\n",
        "\n",
        "# This will trigger downloading model\n",
        "print(\"Downloading if not downloaded Coqui XTTS V2\")\n",
        "from TTS.utils.manage import ModelManager\n",
        "\n",
        "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "ModelManager().download_model(model_name)\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), model_name.replace(\"/\", \"--\"))\n",
        "print(\"XTTS downloaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ioRt7sJoNU",
        "outputId": "5790578b-a959-4738-dbc8-d525c14733bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export newer ffmpeg binary for denoise filter\n",
            "Make ffmpeg binary executable\n",
            "Downloading if not downloaded Coqui XTTS V2\n",
            " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n",
            " > Model's license - CPML\n",
            " > Check https://coqui.ai/cpml.txt for more info.\n",
            "XTTS downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True,\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "DEVICE_ASSERT_DETECTED = 0\n",
        "DEVICE_ASSERT_PROMPT = None\n",
        "DEVICE_ASSERT_LANG = None\n",
        "\n",
        "supported_languages = config.languages\n"
      ],
      "metadata": {
        "id": "6HyR4IDBJqjL",
        "outputId": "9a01d26a-6411-42bf-9003-22a9341b4744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-09-02 17:55:37,643] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-09-02 17:55:39,794] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-09-02 17:55:39,796] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
            "[2024-09-02 17:55:39,799] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
            "[2024-09-02 17:55:39,801] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/transformer_inference...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/transformer_inference/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module transformer_inference...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load transformer_inference op: 82.68424773216248 seconds\n",
            "[2024-09-02 17:57:03,228] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module transformer_inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import re\n",
        "import datetime\n",
        "import csv\n",
        "from io import StringIO\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "ad278dN2TzT-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, max_length=133):\n",
        "    return textwrap.wrap(text, width=max_length, break_long_words=False)\n"
      ],
      "metadata": {
        "id": "AhUhgkQOT5LU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_silence(duration_seconds, file_path, sample_rate=24000):\n",
        "    # تعداد نمونه‌ها به ازای مدت زمان\n",
        "    num_samples = int(duration_seconds * sample_rate)\n",
        "    # ایجاد آرایه‌ای از صفرها (صداهای خالی)\n",
        "    silence = np.zeros(num_samples, dtype=np.float32)\n",
        "    # ذخیره فایل WAV\n",
        "    torchaudio.save(file_path, torch.tensor([silence]), sample_rate)"
      ],
      "metadata": {
        "id": "j2vhMRui43GD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(prompt, language, audio_file_pth=None, mic_file_path=None, use_mic=False, voice_cleanup=False, no_lang_auto_detect=False, agree=True, output_file=None):\n",
        "    if agree:\n",
        "\n",
        "\n",
        "        speaker_wav = audio_file_pth\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            prompt = re.sub(\"([^\\x00-\\x7F]|\\w)(\\.|\\。|\\?)\", r\"\\1 \\2\\2\", prompt)\n",
        "            print(\"Generating new audio...\")\n",
        "            # t0 = time.time() # زمان شروع فرآیند تولید صوت\n",
        "            out = model.inference(\n",
        "                prompt,\n",
        "                language,\n",
        "                *model.get_conditioning_latents(audio_path=speaker_wav, gpt_cond_len=30, gpt_cond_chunk_len=4, max_ref_length=60),\n",
        "                repetition_penalty=5.0,\n",
        "                temperature=0.75,\n",
        "            )\n",
        "            # inference_time = time.time() - t0\n",
        "            # print(f\"Time to generate audio: {round(inference_time * 1000)} milliseconds\")\n",
        "            # real_time_factor = (time.time() - t0) / out['wav'].shape[-1] * 24000\n",
        "            # print(f\"Real-time factor (RTF): {real_time_factor}\")\n",
        "            torchaudio.save(output_file, torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "            print(\"Audio saved to  \"+output_file + \"  sentence : \" + prompt)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"device-side assert\" in str(e):\n",
        "                print(f\"Exit due to: Unrecoverable exception caused by language:{language} prompt:{prompt}\")\n",
        "                print(\"Unhandled Exception encounter, please retry in a minute\")\n",
        "                print(\"Cuda device-assert Runtime encountered need restart\")\n",
        "                if not DEVICE_ASSERT_DETECTED:\n",
        "                    DEVICE_ASSERT_DETECTED = 1\n",
        "                    DEVICE_ASSERT_PROMPT = prompt\n",
        "                    DEVICE_ASSERT_LANG = language\n",
        "\n",
        "                error_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "                error_data = [\n",
        "                    error_time,\n",
        "                    prompt,\n",
        "                    language,\n",
        "                    audio_file_pth,\n",
        "                    mic_file_path,\n",
        "                    use_mic,\n",
        "                    voice_cleanup,\n",
        "                    no_lang_auto_detect,\n",
        "                    agree,\n",
        "                ]\n",
        "                error_data = [str(e) if type(e) != str else e for e in error_data]\n",
        "                print(error_data)\n",
        "                write_io = StringIO()\n",
        "                csv.writer(write_io).writerows([error_data])\n",
        "                csv_upload = write_io.getvalue().encode()\n",
        "\n",
        "                filename = error_time + \"_\" + str(uuid.uuid4()) + \".csv\"\n",
        "                print(\"Writing error csv\")\n",
        "                error_api = HfApi()\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=csv_upload,\n",
        "                    path_in_repo=filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                print(\"Writing error reference audio\")\n",
        "                speaker_filename = error_time + \"_reference_\" + str(uuid.uuid4()) + \".wav\"\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=speaker_wav,\n",
        "                    path_in_repo=speaker_filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                space = api.get_space_runtime(repo_id=repo_id)\n",
        "                if space.stage != \"BUILDING\":\n",
        "                    api.restart_space(repo_id=repo_id)\n",
        "                else:\n",
        "                    print(\"TRIED TO RESTART but space is building\")\n",
        "            else:\n",
        "                if \"Failed to decode\" in str(e):\n",
        "                    print(\"Speaker encoding error\", str(e))\n",
        "                else:\n",
        "                    print(\"RuntimeError: non device-side assert error:\", str(e))\n",
        "                return None\n",
        "\n",
        "        return output_file\n"
      ],
      "metadata": {
        "id": "G-w6GgCEUGRW"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_speech(prompt, language_code, chunk_id):\n",
        "    output_file = f\"chunk_{chunk_id}.wav\"\n",
        "    language_code = \"en\"\n",
        "    audio_file_path = '/content/5.mp3'  # Path to reference audio file if needed\n",
        "    mic_file_path = None  # Path to microphone recorded audio if needed\n",
        "    use_microphone = False\n",
        "    voice_cleanup = True\n",
        "    disable_lang_auto_detect = True\n",
        "\n",
        "\n",
        "    speaker_wav = audio_file_path\n",
        "\n",
        "    # Filtering for microphone input\n",
        "    lowpassfilter = denoise = trim = loudness = True\n",
        "    lowpass_highpass = \"lowpass=8000,highpass=75,\" if lowpassfilter else \"\"\n",
        "    trim_silence = \"areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,\" if trim else \"\"\n",
        "\n",
        "    out_filename = speaker_wav + \"filter.wav\"\n",
        "    shell_command = f\"./ffmpeg -y -i {speaker_wav} -af {lowpass_highpass}{trim_silence} {out_filename}\".split(\" \")\n",
        "    subprocess.run(shell_command, capture_output=False, text=True, check=True)\n",
        "    speaker_wav = out_filename\n",
        "\n",
        "    return text_to_speech(\n",
        "        prompt=prompt,\n",
        "        language=language_code,\n",
        "        audio_file_pth=speaker_wav,\n",
        "        mic_file_path=mic_file_path,\n",
        "        use_mic=use_microphone,\n",
        "        voice_cleanup=voice_cleanup,\n",
        "        no_lang_auto_detect=disable_lang_auto_detect,\n",
        "        agree=True,\n",
        "        output_file= output_file)"
      ],
      "metadata": {
        "id": "hOL9GLg4YSmh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to combine multiple audio files into one\n",
        "def combine_audio_files(audio_files, output_file):\n",
        "\n",
        "    with open(\"file_list.txt\", \"w\") as file_list:\n",
        "      for audio_file in audio_files:\n",
        "          file_list.write(f\"file '{audio_file}'\\n\")\n",
        "\n",
        "    command = [\"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"file_list.txt\", \"-c\", \"copy\", output_file]\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        print(f\"Audio files successfully combined into {output_file}\")\n",
        "        print(result.stdout)\n",
        "        print(result.stderr)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error occurred during combining audio files: {e}\")\n",
        "        print(e.stdout)\n",
        "        print(e.stderr)\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "      os.remove(audio_file)\n",
        "\n",
        "    # with open(output_file, 'wb') as outfile:\n",
        "    #     for audio_file in audio_files:\n",
        "    #         with open(audio_file, 'rb') as infile:\n",
        "    #             outfile.write(infile.read())\n",
        "            # Clean up temporary files\n",
        "            # os.remove(audio_file)"
      ],
      "metadata": {
        "id": "FFhNU1zhXu52"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_to_speech(text, language_code):\n",
        "    # Split text into chunks of 200 characters\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    sentences = re.split(r'(?<=[.!?]|\\[|\\])\\s+', text)\n",
        "\n",
        "    all_audio_files = []\n",
        "\n",
        "\n",
        "    if os.path.isfile(\"combined_output.wav\"):\n",
        "      os.remove(\"combined_output.wav\")\n",
        "\n",
        "    total_sentences = len(sentences)\n",
        "    for idx, sentence in enumerate(sentences):\n",
        "        print(f\"Processing sentence {idx + 1} of {total_sentences}...\")\n",
        "        temp_file = generate_speech(sentence, language_code, idx + 1)\n",
        "        if os.path.exists(temp_file):\n",
        "            all_audio_files.append(temp_file)\n",
        "\n",
        "            # ایجاد فایل صوتی خالی با مدت زمان رندوم\n",
        "            silence_duration = random.uniform(1, 2)  # مدت زمان رندوم بین 1 تا 2 ثانیه\n",
        "            silence_file = f\"silence_{idx + 1}.wav\"\n",
        "            create_silence(silence_duration, silence_file)\n",
        "            all_audio_files.append(silence_file)\n",
        "        else:\n",
        "            print(f\"Failed to generate audio for sentence {idx + 1}.\")\n",
        "\n",
        "    # Combine all audio files into one\n",
        "    if all_audio_files:\n",
        "        combined_audio = \"combined_output.wav\"\n",
        "        combine_audio_files(all_audio_files, combined_audio)\n",
        "        print(f\"All audio files combined into {combined_audio}\")\n",
        "\n",
        "        files.download(\"combined_output.wav\")\n",
        "\n",
        "    else:\n",
        "        print(\"No audio files to combine.\")"
      ],
      "metadata": {
        "id": "qn9SMN3uUVWN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "prompt_text = \"\"\"\n",
        "\n",
        "Hello\n",
        "\n",
        "I’m hamjam, and in today’s video, we’re going to explore [When I realized this, I changed my life in 90 days].\n",
        "\n",
        "I can't emphasize enough how powerful this video can be in shaping your journey. In just a few minutes, you'll understand why. But first, let me ask you a question: How many weeks do you think the average person lives? Don’t overthink it—just say the first number that comes to mind. I guessed 96,000 weeks. My brother said 100,000 weeks. Some friends guessed 150,000 or even 200,000 weeks. But do you know what's interesting? The average person only lives around 4,000 weeks.\n",
        "\n",
        "It’s surprising, isn’t it? When you think about life in terms of weeks, the number seems so small. And when you consider that you might have already spent 1,000 or more of those weeks, it becomes clear how precious time really is. In this video, we’re going to decide what to do with the weeks you have left. Right now, your brain might be telling you to skip this, to watch something more fun instead. But let me tell you this: in a year, two years, or even five years from now, you might wish you had watched this all the way through and made a decision.\n",
        "\n",
        "You see, most people live robotic lives. They wake up tired because they stayed up late scrolling through their phones. They go to a job they don’t like, come home feeling drained, and distract themselves with more screens. Day by day, their remaining weeks slip away, unnoticed, until they retire—looking back at their lives, wondering where the time went.\n",
        "\n",
        "Don’t let that be you. Don’t wait until you have only a few hundred weeks left to live and wonder why you didn’t make better use of your time. The truth is, most people never think about death; they live as if they’ll live forever, stuck in routines that offer no real satisfaction. They’re zombies, going through the motions without ever really being present in their own lives.\n",
        "\n",
        "But you have a choice. You can decide, right now, how you want to spend the weeks you have left. You can choose to live with intention, to pursue your passions, to be fully present in each moment. Or, you can do nothing and end up like the rest—living a life full of regrets, looking back and wishing you had done things differently.\n",
        "\n",
        "This video isn’t meant to scare you; it’s meant to empower you. It’s a reminder that you don’t have to live like everyone else. You don’t have to be stuck in a cycle of endless distraction, giving in to every impulse for instant gratification. You can choose to break free, to focus, to build a life you’re proud of.\n",
        "\n",
        "But that choice is yours to make. I can’t make it for you. I can only guide you to the edge of this realization—you have to take the leap. So, as you watch this video, really think about how you want to live. Are you going to be the best version of yourself, or are you going to settle for less?\n",
        "\n",
        "Remember, the pain of discipline weighs ounces, but the pain of regret weighs tons. The weeks are ticking by—how are you going to spend them?\n",
        "\n",
        "I hope you found today’s video helpful and inspiring. If you enjoyed it, please give us a thumbs up and share it with anyone who might benefit from it.\n",
        "\n",
        "Remember to subscribe if you haven’t already, so you never miss out on our latest tips and insights. Feel free to leave a comment below with your thoughts or any questions you have — I love hearing from you!\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "process_text_to_speech(prompt_text, language_code=\"en\")"
      ],
      "metadata": {
        "id": "3ZUz9btqUaVX",
        "outputId": "dcf9a27e-86f9-463c-9a9a-1e8fe690d8b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sentence 1 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_1.wav  sentence : \n",
            "\n",
            "Hello \n",
            "\n",
            "I’m hamjam, and in today’s video, we’re going to explore [When I realized this, I changed my life in 90 days].\n",
            "Processing sentence 2 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_2.wav  sentence : I can't emphasize enough how powerful this video can be in shaping your journey ..\n",
            "Processing sentence 3 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_3.wav  sentence : In just a few minutes, you'll understand why ..\n",
            "Processing sentence 4 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_4.wav  sentence : But first, let me ask you a question: How many weeks do you think the average person lives ??\n",
            "Processing sentence 5 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_5.wav  sentence : Don’t overthink it—just say the first number that comes to mind ..\n",
            "Processing sentence 6 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_6.wav  sentence : I guessed 96,000 weeks ..\n",
            "Processing sentence 7 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_7.wav  sentence : My brother said 100,000 weeks ..\n",
            "Processing sentence 8 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_8.wav  sentence : Some friends guessed 150,000 or even 200,000 weeks ..\n",
            "Processing sentence 9 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_9.wav  sentence : But do you know what's interesting ??\n",
            "Processing sentence 10 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_10.wav  sentence : The average person only lives around 4,000 weeks ..\n",
            "Processing sentence 11 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_11.wav  sentence : It’s surprising, isn’t it ??\n",
            "Processing sentence 12 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_12.wav  sentence : When you think about life in terms of weeks, the number seems so small ..\n",
            "Processing sentence 13 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_13.wav  sentence : And when you consider that you might have already spent 1,000 or more of those weeks, it becomes clear how precious time really is ..\n",
            "Processing sentence 14 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_14.wav  sentence : In this video, we’re going to decide what to do with the weeks you have left ..\n",
            "Processing sentence 15 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_15.wav  sentence : Right now, your brain might be telling you to skip this, to watch something more fun instead ..\n",
            "Processing sentence 16 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_16.wav  sentence : But let me tell you this: in a year, two years, or even five years from now, you might wish you had watched this all the way through and made a decision ..\n",
            "Processing sentence 17 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_17.wav  sentence : You see, most people live robotic lives ..\n",
            "Processing sentence 18 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_18.wav  sentence : They wake up tired because they stayed up late scrolling through their phones ..\n",
            "Processing sentence 19 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_19.wav  sentence : They go to a job they don’t like, come home feeling drained, and distract themselves with more screens ..\n",
            "Processing sentence 20 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_20.wav  sentence : Day by day, their remaining weeks slip away, unnoticed, until they retire—looking back at their lives, wondering where the time went ..\n",
            "Processing sentence 21 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_21.wav  sentence : Don’t let that be you ..\n",
            "Processing sentence 22 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_22.wav  sentence : Don’t wait until you have only a few hundred weeks left to live and wonder why you didn’t make better use of your time ..\n",
            "Processing sentence 23 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_23.wav  sentence : The truth is, most people never think about death; they live as if they’ll live forever, stuck in routines that offer no real satisfaction ..\n",
            "Processing sentence 24 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_24.wav  sentence : They’re zombies, going through the motions without ever really being present in their own lives ..\n",
            "Processing sentence 25 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_25.wav  sentence : But you have a choice ..\n",
            "Processing sentence 26 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_26.wav  sentence : You can decide, right now, how you want to spend the weeks you have left ..\n",
            "Processing sentence 27 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_27.wav  sentence : You can choose to live with intention, to pursue your passions, to be fully present in each moment ..\n",
            "Processing sentence 28 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_28.wav  sentence : Or, you can do nothing and end up like the rest—living a life full of regrets, looking back and wishing you had done things differently ..\n",
            "Processing sentence 29 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_29.wav  sentence : This video isn’t meant to scare you; it’s meant to empower you ..\n",
            "Processing sentence 30 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_30.wav  sentence : It’s a reminder that you don’t have to live like everyone else ..\n",
            "Processing sentence 31 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_31.wav  sentence : You don’t have to be stuck in a cycle of endless distraction, giving in to every impulse for instant gratification ..\n",
            "Processing sentence 32 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_32.wav  sentence : You can choose to break free, to focus, to build a life you’re proud of ..\n",
            "Processing sentence 33 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_33.wav  sentence : But that choice is yours to make ..\n",
            "Processing sentence 34 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_34.wav  sentence : I can’t make it for you ..\n",
            "Processing sentence 35 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_35.wav  sentence : I can only guide you to the edge of this realization—you have to take the leap ..\n",
            "Processing sentence 36 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_36.wav  sentence : So, as you watch this video, really think about how you want to live ..\n",
            "Processing sentence 37 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_37.wav  sentence : Are you going to be the best version of yourself, or are you going to settle for less ??\n",
            "Processing sentence 38 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_38.wav  sentence : Remember, the pain of discipline weighs ounces, but the pain of regret weighs tons ..\n",
            "Processing sentence 39 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_39.wav  sentence : The weeks are ticking by—how are you going to spend them ??\n",
            "Processing sentence 40 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_40.wav  sentence : I hope you found today’s video helpful and inspiring ..\n",
            "Processing sentence 41 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_41.wav  sentence : If you enjoyed it, please give us a thumbs up and share it with anyone who might benefit from it ..\n",
            "Processing sentence 42 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_42.wav  sentence : Remember to subscribe if you haven’t already, so you never miss out on our latest tips and insights ..\n",
            "Processing sentence 43 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_43.wav  sentence : Feel free to leave a comment below with your thoughts or any questions you have — I love hearing from you!\n",
            "Processing sentence 44 of 44...\n",
            "Generating new audio...\n",
            "Audio saved to  chunk_44.wav  sentence : \n",
            "Audio files successfully combined into combined_output.wav\n",
            "\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, concat, from 'file_list.txt':\n",
            "  Duration: N/A, start: 0.000000, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Output #0, wav, to 'combined_output.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "size=       4kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
            "size=    9216kB time=00:03:19.99 bitrate= 377.5kbits/s speed= 400x    \n",
            "size=   13777kB time=00:04:53.87 bitrate= 384.0kbits/s speed= 415x    \n",
            "video:0kB audio:13776kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000553%\n",
            "\n",
            "All audio files combined into combined_output.wav\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_58a36666-1b36-4642-9154-ee4b818971bb\", \"combined_output.wav\", 14107208)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "command = [\n",
        "    \"ffmpeg\",\n",
        "    \"-y\",\n",
        "    \"-i\", \"combined_output.wav\",\n",
        "    \"-filter:a\", \"atempo=0.93\",\n",
        "    \"output_final.wav\"\n",
        "]\n",
        "\n",
        "\n",
        "# اجرای فرمان FFmpeg\n",
        "try:\n",
        "    result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    print(\"Command executed successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(result.stdout)\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(\"Error occurred:\")\n",
        "    print(e.stderr)"
      ],
      "metadata": {
        "id": "Crue82UIiweh",
        "outputId": "8eb4bf11-563e-4f84-f24e-93fd4f06276d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Command executed successfully.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}