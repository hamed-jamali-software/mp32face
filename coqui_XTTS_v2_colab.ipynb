{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamed-jamali-software/mp32face/blob/main/coqui_XTTS_v2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "outputId": "8317b7f0-8144-435e-d7ad-a94714ce4d1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'xtts2-hf'...\n",
            "remote: Enumerating objects: 518, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 518 (delta 2), reused 3 (delta 1), pack-reused 512 (from 1)\u001b[K\n",
            "Receiving objects: 100% (518/518), 716.12 KiB | 13.26 MiB/s, done.\n",
            "Resolving deltas: 100% (311/311), done.\n",
            "Downloading examples/female.wav (1.0 MB)\n",
            "Error downloading object: examples/female.wav (89a4fa9): Smudge error: Error downloading examples/female.wav (89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02): [89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02] Object does not exist on the server: [404] Object does not exist on the server\n",
            "\n",
            "Errors logged to /content/xtts2-hf/.git/lfs/logs/20240829T123812.905244375.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: examples/female.wav: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "/content/xtts2-hf\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.3/933.3 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: 2.0.0: No such file or directory\n",
            "--2024-08-29 12:40:15--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.114, 3.163.189.90, 3.163.189.74, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725194415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTE5NDQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=BE4Owvqz066ZHPrTvbNcyYO6%7EQauLNCQciKsM7OVKpSqdKwbXU88%7ExLrDZePO4HbJAL6badK%7EE7oXH%7E60hS6ahjDc0YIpaPeifM1tRW2ZttwYN8MeE5%7EBXdRxjjAsh8MQh2-n3cBT6%7EiRHWgPJ8eEZ7L5uklQ7lZ1D6IZ3dwep23d2Diag2G9Yq1nRGzHBNRGTF9P9mOKBXs99CFkfE-bGtnZW3SlrS0PGNN0-sFCWuB12cXT1oj4PN-x29eT0eN7rlVeXwB7eCcbv-g45BLY2olA%7EtwDokrcXT3sJkpnRhqYJ9HqDuYCuvFcOEKeQGOZ97tKPr-A7lF52Po7Rc6GQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-29 12:40:15--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725194415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTE5NDQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=BE4Owvqz066ZHPrTvbNcyYO6%7EQauLNCQciKsM7OVKpSqdKwbXU88%7ExLrDZePO4HbJAL6badK%7EE7oXH%7E60hS6ahjDc0YIpaPeifM1tRW2ZttwYN8MeE5%7EBXdRxjjAsh8MQh2-n3cBT6%7EiRHWgPJ8eEZ7L5uklQ7lZ1D6IZ3dwep23d2Diag2G9Yq1nRGzHBNRGTF9P9mOKBXs99CFkfE-bGtnZW3SlrS0PGNN0-sFCWuB12cXT1oj4PN-x29eT0eN7rlVeXwB7eCcbv-g45BLY2olA%7EtwDokrcXT3sJkpnRhqYJ9HqDuYCuvFcOEKeQGOZ97tKPr-A7lF52Po7Rc6GQ__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.94.14, 108.138.94.23, 108.138.94.25, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.94.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002030 (979K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/female.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 978.54K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-08-29 12:40:15 (24.6 MB/s) - ‘/content/xtts2-hf/examples/female.wav’ saved [1002030/1002030]\n",
            "\n",
            "--2024-08-29 12:40:15--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.114, 3.163.189.90, 3.163.189.74, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725194415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTE5NDQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=av%7EVyViWXuWxDbSxyLYidW2JdVWb%7EgK3LCZ1k0ZReag4rZ1aRbZ-xIT5tnkr7rERxEjGCyh6SB4KbW7o1unDekYURkCKWq7cUc3uBQGscw9mhpy6kwVikjHwq%7EVVZMLKkajtdLDawhtdfjP%7Ef7Jwx0RK84JUp5jTwNwHTV6Y5%7EY3kTO5Smxlu8r0RRz2Njey9jGlnzyh5ZETTBeqD4mfXYXy8fYeKLSn5RhP3NEU%7EtMBnCtZSdAQJFbYC%7EbTPvyLFAoTSuwPfwnQZqL1Imr5UuVzFuEVUTIanuoo3SIhyTMIDHLXAtQi0Ju-r50N71bzZQl1ZzaW5L0HO0KHwp%7EgrA__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-29 12:40:15--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725194415&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTE5NDQxNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=av%7EVyViWXuWxDbSxyLYidW2JdVWb%7EgK3LCZ1k0ZReag4rZ1aRbZ-xIT5tnkr7rERxEjGCyh6SB4KbW7o1unDekYURkCKWq7cUc3uBQGscw9mhpy6kwVikjHwq%7EVVZMLKkajtdLDawhtdfjP%7Ef7Jwx0RK84JUp5jTwNwHTV6Y5%7EY3kTO5Smxlu8r0RRz2Njey9jGlnzyh5ZETTBeqD4mfXYXy8fYeKLSn5RhP3NEU%7EtMBnCtZSdAQJFbYC%7EbTPvyLFAoTSuwPfwnQZqL1Imr5UuVzFuEVUTIanuoo3SIhyTMIDHLXAtQi0Ju-r50N71bzZQl1ZzaW5L0HO0KHwp%7EgrA__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.94.23, 108.138.94.25, 108.138.94.14, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.94.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 762126 (744K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/male.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 744.26K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-08-29 12:40:15 (23.4 MB/s) - ‘/content/xtts2-hf/examples/male.wav’ saved [762126/762126]\n",
            "\n",
            "--2024-08-29 12:40:15--  https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.114, 3.163.189.90, 3.163.189.74, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725194416&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTE5NDQxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jvFKYIVUSnKyWEK2XodcGayAXl5Nmh6I4Bk37ib5k1Wu6vzzX3uG-I9H-faMeHEEokW%7E246yJez59M7oIBHc3aP5s3cd8OWsM4QgZ7B-G9BU5dHkoYtYLxe8Wa5CShsR03T6WL2os2VDRc%7EKR0%7E2TBA78wgnKRCx-%7EYXHXrmHL4JgQtmq8RUbtzmukbj5-JF0Ph5up6o4zHhQWt6DuWJ%7EKQGLGiwuPnqkiTYKfeB29CCNLvaWdnW5fyM0S9h5-E0bXd6FCpJ5qUJYaaAOtro5X97g4LcYFNLhVM2YpOmkE1Y4HQX5wmhh3IHEMY69rNKNCnUzfpHAJRL7SdB-LftiA__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-29 12:40:16--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725194416&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTE5NDQxNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jvFKYIVUSnKyWEK2XodcGayAXl5Nmh6I4Bk37ib5k1Wu6vzzX3uG-I9H-faMeHEEokW%7E246yJez59M7oIBHc3aP5s3cd8OWsM4QgZ7B-G9BU5dHkoYtYLxe8Wa5CShsR03T6WL2os2VDRc%7EKR0%7E2TBA78wgnKRCx-%7EYXHXrmHL4JgQtmq8RUbtzmukbj5-JF0Ph5up6o4zHhQWt6DuWJ%7EKQGLGiwuPnqkiTYKfeB29CCNLvaWdnW5fyM0S9h5-E0bXd6FCpJ5qUJYaaAOtro5X97g4LcYFNLhVM2YpOmkE1Y4HQX5wmhh3IHEMY69rNKNCnUzfpHAJRL7SdB-LftiA__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.94.23, 108.138.94.14, 108.138.94.122, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.94.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29207056 (28M) [application/zip]\n",
            "Saving to: ‘/content/xtts2-hf/ffmpeg.zip’\n",
            "\n",
            "/content/xtts2-hf/f 100%[===================>]  27.85M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-08-29 12:40:16 (234 MB/s) - ‘/content/xtts2-hf/ffmpeg.zip’ saved [29207056/29207056]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/xtts2-hf\n",
        "%cd /content/xtts2-hf\n",
        "!pip install -q gradio==3.50.2 TTS==0.21.1 langid unidic-lite unidic deepspeed\n",
        "!pip install -q numpy<2.0.0 -U\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav -O /content/xtts2-hf/examples/female.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav -O /content/xtts2-hf/examples/male.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip -O /content/xtts2-hf/ffmpeg.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "T_f3x6IF3U4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io, os, stat\n",
        "import subprocess\n",
        "import random\n",
        "from zipfile import ZipFile\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import langid\n",
        "import re\n",
        "from zipfile import ZipFile\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "from huggingface_hub import HfApi\n"
      ],
      "metadata": {
        "id": "FBIbnUWp3xnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download for mecab\n",
        "os.system('python -m unidic download')\n",
        "\n",
        "# By using XTTS you agree to CPML license https://coqui.ai/cpml\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "api = HfApi(token=HF_TOKEN)\n",
        "repo_id = \"coqui/xtts\"\n",
        "\n",
        "# Use newer ffmpeg binary for Ubuntu20 to use denoising for microphone input\n",
        "print(\"Export newer ffmpeg binary for denoise filter\")\n",
        "ZipFile(\"ffmpeg.zip\").extractall()\n",
        "print(\"Make ffmpeg binary executable\")\n",
        "st = os.stat(\"ffmpeg\")\n",
        "os.chmod(\"ffmpeg\", st.st_mode | stat.S_IEXEC)\n",
        "\n",
        "# This will trigger downloading model\n",
        "print(\"Downloading if not downloaded Coqui XTTS V2\")\n",
        "from TTS.utils.manage import ModelManager\n",
        "\n",
        "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "ModelManager().download_model(model_name)\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), model_name.replace(\"/\", \"--\"))\n",
        "print(\"XTTS downloaded\")"
      ],
      "metadata": {
        "id": "03ioRt7sJoNU",
        "outputId": "c00152a5-b9cb-4ae2-8771-54d258aeb538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export newer ffmpeg binary for denoise filter\n",
            "Make ffmpeg binary executable\n",
            "Downloading if not downloaded Coqui XTTS V2\n",
            " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n",
            " > Model's license - CPML\n",
            " > Check https://coqui.ai/cpml.txt for more info.\n",
            "XTTS downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True,\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "DEVICE_ASSERT_DETECTED = 0\n",
        "DEVICE_ASSERT_PROMPT = None\n",
        "DEVICE_ASSERT_LANG = None\n",
        "\n",
        "supported_languages = config.languages\n"
      ],
      "metadata": {
        "id": "6HyR4IDBJqjL",
        "outputId": "68b85fa5-892f-41a9-e279-1083d7f2ed31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-29 12:42:37,012] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-08-29 12:42:39,722] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-08-29 12:42:39,724] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
            "[2024-08-29 12:42:39,728] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
            "[2024-08-29 12:42:39,729] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/transformer_inference...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/transformer_inference/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module transformer_inference...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load transformer_inference op: 83.93317246437073 seconds\n",
            "[2024-08-29 12:44:04,359] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module transformer_inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def text_to_speech(prompt, language, audio_file_pth=None, mic_file_path=None, use_mic=False, voice_cleanup=False, no_lang_auto_detect=False, agree=True):\n",
        "    if agree:\n",
        "        if language not in supported_languages:\n",
        "            print(f\"Language you put {language} in is not in our Supported Languages, please choose from dropdown\")\n",
        "            return None\n",
        "\n",
        "        language_predicted = langid.classify(prompt)[0].strip()\n",
        "        if language_predicted == \"zh\":\n",
        "            language_predicted = \"zh-cn\"\n",
        "\n",
        "        if len(prompt) > 15:\n",
        "            if language_predicted != language and not no_lang_auto_detect:\n",
        "                print(f\"It looks like your text isn’t the language you chose , if you’re sure the text is the same language you chose, please check disable language auto-detection checkbox\")\n",
        "                return None\n",
        "\n",
        "        if use_mic:\n",
        "            if mic_file_path is not None:\n",
        "                speaker_wav = mic_file_path\n",
        "            else:\n",
        "                print(\"Please record your voice with Microphone, or uncheck Use Microphone to use reference audios\")\n",
        "                return None\n",
        "        else:\n",
        "            speaker_wav = audio_file_pth\n",
        "\n",
        "        # Filtering for microphone input\n",
        "        lowpassfilter = denoise = trim = loudness = True\n",
        "        lowpass_highpass = \"lowpass=8000,highpass=75,\" if lowpassfilter else \"\"\n",
        "        trim_silence = \"areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,\" if trim else \"\"\n",
        "\n",
        "        if voice_cleanup:\n",
        "            try:\n",
        "                out_filename = speaker_wav + str(uuid.uuid4()) + \".wav\"\n",
        "                shell_command = f\"./ffmpeg -y -i {speaker_wav} -af {lowpass_highpass}{trim_silence} {out_filename}\".split(\" \")\n",
        "                subprocess.run(shell_command, capture_output=False, text=True, check=True)\n",
        "                speaker_wav = out_filename\n",
        "                print(\"Filtered microphone input\")\n",
        "            except subprocess.CalledProcessError:\n",
        "                print(\"Error: failed filtering, use original microphone input\")\n",
        "\n",
        "        if len(prompt) < 2:\n",
        "            print(\"Please give a longer prompt text\")\n",
        "            return None\n",
        "        if len(prompt) > 200:\n",
        "            print(\"Text length limited to 200 characters for this demo, please try shorter text. You can clone this space and edit code for your own usage\")\n",
        "            return None\n",
        "\n",
        "        global DEVICE_ASSERT_DETECTED\n",
        "        if DEVICE_ASSERT_DETECTED:\n",
        "            global DEVICE_ASSERT_PROMPT\n",
        "            global DEVICE_ASSERT_LANG\n",
        "            print(f\"Unrecoverable exception caused by language:{DEVICE_ASSERT_LANG} prompt:{DEVICE_ASSERT_PROMPT}\")\n",
        "            space = api.get_space_runtime(repo_id=repo_id)\n",
        "            if space.stage != \"BUILDING\":\n",
        "                api.restart_space(repo_id=repo_id)\n",
        "            else:\n",
        "                print(\"TRIED TO RESTART but space is building\")\n",
        "\n",
        "        try:\n",
        "            prompt = re.sub(\"([^\\x00-\\x7F]|\\w)(\\.|\\。|\\?)\", r\"\\1 \\2\\2\", prompt)\n",
        "            print(\"Generating new audio...\")\n",
        "            t0 = time.time()\n",
        "            out = model.inference(\n",
        "                prompt,\n",
        "                language,\n",
        "                *model.get_conditioning_latents(audio_path=speaker_wav, gpt_cond_len=30, gpt_cond_chunk_len=4, max_ref_length=60),\n",
        "                repetition_penalty=5.0,\n",
        "                temperature=0.75,\n",
        "            )\n",
        "            inference_time = time.time() - t0\n",
        "            print(f\"Time to generate audio: {round(inference_time * 1000)} milliseconds\")\n",
        "            real_time_factor = (time.time() - t0) / out['wav'].shape[-1] * 24000\n",
        "            print(f\"Real-time factor (RTF): {real_time_factor}\")\n",
        "            torchaudio.save(\"output.wav\", torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "            print(\"Audio saved to output.wav\")\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"device-side assert\" in str(e):\n",
        "                print(f\"Exit due to: Unrecoverable exception caused by language:{language} prompt:{prompt}\")\n",
        "                print(\"Unhandled Exception encounter, please retry in a minute\")\n",
        "                print(\"Cuda device-assert Runtime encountered need restart\")\n",
        "                if not DEVICE_ASSERT_DETECTED:\n",
        "                    DEVICE_ASSERT_DETECTED = 1\n",
        "                    DEVICE_ASSERT_PROMPT = prompt\n",
        "                    DEVICE_ASSERT_LANG = language\n",
        "\n",
        "                error_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "                error_data = [\n",
        "                    error_time,\n",
        "                    prompt,\n",
        "                    language,\n",
        "                    audio_file_pth,\n",
        "                    mic_file_path,\n",
        "                    use_mic,\n",
        "                    voice_cleanup,\n",
        "                    no_lang_auto_detect,\n",
        "                    agree,\n",
        "                ]\n",
        "                error_data = [str(e) if type(e) != str else e for e in error_data]\n",
        "                print(error_data)\n",
        "                write_io = StringIO()\n",
        "                csv.writer(write_io).writerows([error_data])\n",
        "                csv_upload = write_io.getvalue().encode()\n",
        "\n",
        "                filename = error_time + \"_\" + str(uuid.uuid4()) + \".csv\"\n",
        "                print(\"Writing error csv\")\n",
        "                error_api = HfApi()\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=csv_upload,\n",
        "                    path_in_repo=filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                print(\"Writing error reference audio\")\n",
        "                speaker_filename = error_time + \"_reference_\" + str(uuid.uuid4()) + \".wav\"\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=speaker_wav,\n",
        "                    path_in_repo=speaker_filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                space = api.get_space_runtime(repo_id=repo_id)\n",
        "                if space.stage != \"BUILDING\":\n",
        "                    api.restart_space(repo_id=repo_id)\n",
        "                else:\n",
        "                    print(\"TRIED TO RESTART but space is building\")\n",
        "            else:\n",
        "                if \"Failed to decode\" in str(e):\n",
        "                    print(\"Speaker encoding error\", str(e))\n",
        "                else:\n",
        "                    print(\"RuntimeError: non device-side assert error:\", str(e))\n",
        "                return None\n",
        "\n",
        "        return \"output.wav\""
      ],
      "metadata": {
        "id": "3FQbDGz2J1Jv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \"Hello, this is a test.\"\n",
        "language_code = \"en\"\n",
        "audio_file_path = '/content/1.mp3'  # Path to reference audio file if needed\n",
        "mic_file_path = None  # Path to microphone recorded audio if needed\n",
        "use_microphone = False\n",
        "voice_cleanup = False\n",
        "disable_lang_auto_detect = False\n",
        "agree_terms = True\n",
        "\n",
        "output_file = text_to_speech(prompt_text, language_code, audio_file_path, mic_file_path, use_microphone, voice_cleanup, disable_lang_auto_detect, agree_terms)\n",
        "if output_file:\n",
        "    print(f\"Audio generated and saved to {output_file}\")\n",
        "else:\n",
        "    print(\"Failed to generate audio.\")"
      ],
      "metadata": {
        "id": "1sDNjrWTJ7IK",
        "outputId": "7bdcee02-1960-4125-b062-57a3f1f6a1db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating new audio...\n",
            "Time to generate audio: 895 milliseconds\n",
            "Real-time factor (RTF): 0.5381790777811637\n",
            "Audio saved to output.wav\n",
            "Audio generated and saved to output.wav\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}