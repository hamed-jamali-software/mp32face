{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamed-jamali-software/mp32face/blob/main/coqui_XTTS_v2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4527574-74d8-4570-84d5-e0fcc775091c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'xtts2-hf'...\n",
            "remote: Enumerating objects: 518, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 518 (delta 2), reused 3 (delta 1), pack-reused 512 (from 1)\u001b[K\n",
            "Receiving objects: 100% (518/518), 716.12 KiB | 2.05 MiB/s, done.\n",
            "Resolving deltas: 100% (311/311), done.\n",
            "Downloading examples/female.wav (1.0 MB)\n",
            "Error downloading object: examples/female.wav (89a4fa9): Smudge error: Error downloading examples/female.wav (89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02): [89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02] Object does not exist on the server: [404] Object does not exist on the server\n",
            "\n",
            "Errors logged to /content/xtts2-hf/.git/lfs/logs/20240829T164341.054644679.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: examples/female.wav: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "/content/xtts2-hf\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.3/933.3 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.7/833.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.22.0 which is incompatible.\n",
            "arviz 0.18.0 requires numpy<2.0,>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "astropy 6.1.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "numexpr 2.10.1 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.22.0 which is incompatible.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "scikit-image 0.23.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "statsmodels 0.14.2 requires numpy>=1.22.3, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: line 1: 2.0.0: No such file or directory\n",
            "--2024-08-29 16:45:41--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725209141&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTIwOTE0MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Ccen7yrC7I%7EPyaxpm4F6SJCIS8ufxfd-aA53GfOfRWh66waikfH2rjq4zWsLk9fFkgXSzDRuYZvRMWvsy9DHVTSOrkw9np2dPWehpVufJOObGEq98NQqkMjdv-iCjE8VidfHuPpUaiNzEO9%7EQuMQXQHn9zjqwQWTG6bkpZLEszNPcZob%7EK480D2fBGksMd7x1ul9ZF1UqCjenNaeXQ4wQ82sfPpr4-0V%7E8VDvhewNeGR2KRvgXHoGdOJyJns62gvSc1bfVA12HOmRgKb19Z3Pf0MWYOpP3y4eSnztOBXlY4s%7ELBQ9s7O%7EOPPgNcfGB%7EI0chMQHutWtC-ty3-FYI%7ERw__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-29 16:45:41--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/89a4fa9a16b6463f852cf9424f72c3d3c87aa83010e89db534c53fcd1ae12c02?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27female.wav%3B+filename%3D%22female.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725209141&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTIwOTE0MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5Lzg5YTRmYTlhMTZiNjQ2M2Y4NTJjZjk0MjRmNzJjM2QzYzg3YWE4MzAxMGU4OWRiNTM0YzUzZmNkMWFlMTJjMDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=Ccen7yrC7I%7EPyaxpm4F6SJCIS8ufxfd-aA53GfOfRWh66waikfH2rjq4zWsLk9fFkgXSzDRuYZvRMWvsy9DHVTSOrkw9np2dPWehpVufJOObGEq98NQqkMjdv-iCjE8VidfHuPpUaiNzEO9%7EQuMQXQHn9zjqwQWTG6bkpZLEszNPcZob%7EK480D2fBGksMd7x1ul9ZF1UqCjenNaeXQ4wQ82sfPpr4-0V%7E8VDvhewNeGR2KRvgXHoGdOJyJns62gvSc1bfVA12HOmRgKb19Z3Pf0MWYOpP3y4eSnztOBXlY4s%7ELBQ9s7O%7EOPPgNcfGB%7EI0chMQHutWtC-ty3-FYI%7ERw__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.65.25.122, 18.65.25.40, 18.65.25.124, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.65.25.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002030 (979K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/female.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 978.54K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-08-29 16:45:41 (23.4 MB/s) - ‘/content/xtts2-hf/examples/female.wav’ saved [1002030/1002030]\n",
            "\n",
            "--2024-08-29 16:45:41--  https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725209141&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTIwOTE0MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ddKpJh4UAsZqtLzu8Zq3Qgj3TsyBPGkc4Und0zVKhP37QVoS880rZkVT7QzEKySq23zVM6FL3Gw93VunPnU9Y9BjoGyb0NpJohaRtvD3rzogmUZMEn-SJUpXqvsxyrjEbdpuFBxUuaNe7Ioey4qNUyigKCx9yynykzog%7ES8Qb9znyoYo0s-0UraRZ9dDgdHHJsU%7E0GLLQX%7EFM--4vY25mzZcdsuEBJCtZvF3SAOaFl2V9hbJRIiXzx3TrKxR41Em0HZG54V0wvUwfrHasg62esC6CwHB-stNx-%7EL1SMymstwdDc6Pfv1WPWK5o%7EDaUbrXUMo2orN6kExKhONmnYtRQ__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-29 16:45:41--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/937c74afad004937e00d1687c68e02210e0c5d93ac072a7c8aeb9ab573517bb1?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27male.wav%3B+filename%3D%22male.wav%22%3B&response-content-type=audio%2Fwave&Expires=1725209141&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTIwOTE0MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzkzN2M3NGFmYWQwMDQ5MzdlMDBkMTY4N2M2OGUwMjIxMGUwYzVkOTNhYzA3MmE3YzhhZWI5YWI1NzM1MTdiYjE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=ddKpJh4UAsZqtLzu8Zq3Qgj3TsyBPGkc4Und0zVKhP37QVoS880rZkVT7QzEKySq23zVM6FL3Gw93VunPnU9Y9BjoGyb0NpJohaRtvD3rzogmUZMEn-SJUpXqvsxyrjEbdpuFBxUuaNe7Ioey4qNUyigKCx9yynykzog%7ES8Qb9znyoYo0s-0UraRZ9dDgdHHJsU%7E0GLLQX%7EFM--4vY25mzZcdsuEBJCtZvF3SAOaFl2V9hbJRIiXzx3TrKxR41Em0HZG54V0wvUwfrHasg62esC6CwHB-stNx-%7EL1SMymstwdDc6Pfv1WPWK5o%7EDaUbrXUMo2orN6kExKhONmnYtRQ__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.65.25.122, 18.65.25.40, 18.65.25.124, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.65.25.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 762126 (744K) [audio/wave]\n",
            "Saving to: ‘/content/xtts2-hf/examples/male.wav’\n",
            "\n",
            "/content/xtts2-hf/e 100%[===================>] 744.26K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-08-29 16:45:41 (19.4 MB/s) - ‘/content/xtts2-hf/examples/male.wav’ saved [762126/762126]\n",
            "\n",
            "--2024-08-29 16:45:41--  https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.17, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.17|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725209141&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTIwOTE0MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=HQf-Uhl8v4bS%7ENA-pZbqlaxcd9-KSlReXwb5h4%7EGXgxJqvkzYgViDk%7EQ5YgMakJfIFZtDfRRpQOPY4OaA6SaHft39hi2I4A1aloVBG6XUbIw7A3%7EP11rTK%7ECf9cmlYBxGgzNVlawLA0NSu6QZsjSKIbcqHV8Hk-7GvNrb3tlksFC2elBwvM3joJzXEsyiLLjw8SmyyOhfc0RyeI2VyBa6u-cCgBPkzL6t%7EF0H0gbybB6q9Z-eTfvm41DJpEFakWK6lk8SOPLZ3PjBs33rN7qtSelRTFacUH1oZHKqiKKKkCELnvet830R%7EtRhdWsp7CwjeGG4Tr8G9xW0OlIwRfvAw__&Key-Pair-Id=K3ESJI6DHPFC7 [following]\n",
            "--2024-08-29 16:45:41--  https://cdn-lfs.huggingface.co/repos/bd/5e/bd5ecae45b2f960165edfb7226a6279b724e75e0e86e0464280540e828128cb9/6c04aa2958762686cf94a3bd1456b4738fd537d19bb0a9b622fc788a5e4ce723?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ffmpeg.zip%3B+filename%3D%22ffmpeg.zip%22%3B&response-content-type=application%2Fzip&Expires=1725209141&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNTIwOTE0MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iZC81ZS9iZDVlY2FlNDViMmY5NjAxNjVlZGZiNzIyNmE2Mjc5YjcyNGU3NWUwZTg2ZTA0NjQyODA1NDBlODI4MTI4Y2I5LzZjMDRhYTI5NTg3NjI2ODZjZjk0YTNiZDE0NTZiNDczOGZkNTM3ZDE5YmIwYTliNjIyZmM3ODhhNWU0Y2U3MjM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=HQf-Uhl8v4bS%7ENA-pZbqlaxcd9-KSlReXwb5h4%7EGXgxJqvkzYgViDk%7EQ5YgMakJfIFZtDfRRpQOPY4OaA6SaHft39hi2I4A1aloVBG6XUbIw7A3%7EP11rTK%7ECf9cmlYBxGgzNVlawLA0NSu6QZsjSKIbcqHV8Hk-7GvNrb3tlksFC2elBwvM3joJzXEsyiLLjw8SmyyOhfc0RyeI2VyBa6u-cCgBPkzL6t%7EF0H0gbybB6q9Z-eTfvm41DJpEFakWK6lk8SOPLZ3PjBs33rN7qtSelRTFacUH1oZHKqiKKKkCELnvet830R%7EtRhdWsp7CwjeGG4Tr8G9xW0OlIwRfvAw__&Key-Pair-Id=K3ESJI6DHPFC7\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.65.25.122, 18.65.25.40, 18.65.25.124, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.65.25.122|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29207056 (28M) [application/zip]\n",
            "Saving to: ‘/content/xtts2-hf/ffmpeg.zip’\n",
            "\n",
            "/content/xtts2-hf/f 100%[===================>]  27.85M   184MB/s    in 0.2s    \n",
            "\n",
            "2024-08-29 16:45:42 (184 MB/s) - ‘/content/xtts2-hf/ffmpeg.zip’ saved [29207056/29207056]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/xtts2-hf\n",
        "%cd /content/xtts2-hf\n",
        "!pip install -q gradio==3.50.2 TTS==0.21.1 langid unidic-lite unidic deepspeed\n",
        "!pip install -q numpy<2.0.0 -U\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/female.wav -O /content/xtts2-hf/examples/female.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/examples/male.wav -O /content/xtts2-hf/examples/male.wav\n",
        "!wget https://huggingface.co/spaces/coqui/xtts/resolve/main/ffmpeg.zip -O /content/xtts2-hf/ffmpeg.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "T_f3x6IF3U4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import io, os, stat\n",
        "import subprocess\n",
        "import random\n",
        "from zipfile import ZipFile\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import langid\n",
        "import re\n",
        "from zipfile import ZipFile\n",
        "from TTS.api import TTS\n",
        "from TTS.tts.configs.xtts_config import XttsConfig\n",
        "from TTS.tts.models.xtts import Xtts\n",
        "from TTS.utils.generic_utils import get_user_data_dir\n",
        "from huggingface_hub import HfApi\n"
      ],
      "metadata": {
        "id": "FBIbnUWp3xnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download for mecab\n",
        "os.system('python -m unidic download')\n",
        "\n",
        "# By using XTTS you agree to CPML license https://coqui.ai/cpml\n",
        "os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
        "\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\")\n",
        "api = HfApi(token=HF_TOKEN)\n",
        "repo_id = \"coqui/xtts\"\n",
        "\n",
        "# Use newer ffmpeg binary for Ubuntu20 to use denoising for microphone input\n",
        "print(\"Export newer ffmpeg binary for denoise filter\")\n",
        "ZipFile(\"ffmpeg.zip\").extractall()\n",
        "print(\"Make ffmpeg binary executable\")\n",
        "st = os.stat(\"ffmpeg\")\n",
        "os.chmod(\"ffmpeg\", st.st_mode | stat.S_IEXEC)\n",
        "\n",
        "# This will trigger downloading model\n",
        "print(\"Downloading if not downloaded Coqui XTTS V2\")\n",
        "from TTS.utils.manage import ModelManager\n",
        "\n",
        "model_name = \"tts_models/multilingual/multi-dataset/xtts_v2\"\n",
        "ModelManager().download_model(model_name)\n",
        "model_path = os.path.join(get_user_data_dir(\"tts\"), model_name.replace(\"/\", \"--\"))\n",
        "print(\"XTTS downloaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03ioRt7sJoNU",
        "outputId": "ce35ca34-1b09-4cde-a545-336fd66c8d3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export newer ffmpeg binary for denoise filter\n",
            "Make ffmpeg binary executable\n",
            "Downloading if not downloaded Coqui XTTS V2\n",
            " > Downloading model to /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v2\n",
            " > Model's license - CPML\n",
            " > Check https://coqui.ai/cpml.txt for more info.\n",
            "XTTS downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = XttsConfig()\n",
        "config.load_json(os.path.join(model_path, \"config.json\"))\n",
        "\n",
        "model = Xtts.init_from_config(config)\n",
        "model.load_checkpoint(\n",
        "    config,\n",
        "    checkpoint_path=os.path.join(model_path, \"model.pth\"),\n",
        "    vocab_path=os.path.join(model_path, \"vocab.json\"),\n",
        "    eval=True,\n",
        "    use_deepspeed=True,\n",
        ")\n",
        "model.cuda()\n",
        "\n",
        "DEVICE_ASSERT_DETECTED = 0\n",
        "DEVICE_ASSERT_PROMPT = None\n",
        "DEVICE_ASSERT_LANG = None\n",
        "\n",
        "supported_languages = config.languages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HyR4IDBJqjL",
        "outputId": "7ddd9023-d527-4ef1-bb5a-7b1e54ebd188"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/TTS/utils/io.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-08-29 16:47:45,010] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-08-29 16:47:47,238] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.15.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-08-29 16:47:47,241] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter replace_method is deprecated. This parameter is no longer needed, please remove from your call to DeepSpeed-inference\n",
            "[2024-08-29 16:47:47,243] [WARNING] [config_utils.py:70:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead\n",
            "[2024-08-29 16:47:47,246] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using /root/.cache/torch_extensions/py310_cu121 as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/py310_cu121/transformer_inference...\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/py310_cu121/transformer_inference/build.ninja...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Building extension module transformer_inference...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to load transformer_inference op: 90.05025482177734 seconds\n",
            "[2024-08-29 16:49:18,238] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 1024, 'intermediate_size': 4096, 'heads': 16, 'num_hidden_layers': -1, 'dtype': torch.float32, 'pre_layer_norm': True, 'norm_type': <NormType.LayerNorm: 1>, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': False, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False, 'use_triton': False, 'triton_autotune': False, 'num_kv': -1, 'rope_theta': 10000, 'invert_mask': True}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading extension module transformer_inference...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "import subprocess\n",
        "import uuid\n",
        "import time\n",
        "import re\n",
        "import datetime\n",
        "import csv\n",
        "from io import StringIO"
      ],
      "metadata": {
        "id": "ad278dN2TzT-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, max_length=200):\n",
        "    return textwrap.wrap(text, width=max_length, break_long_words=False)\n"
      ],
      "metadata": {
        "id": "AhUhgkQOT5LU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(prompt, language, audio_file_pth=None, mic_file_path=None, use_mic=False, voice_cleanup=False, no_lang_auto_detect=False, agree=True, output_file=None):\n",
        "    if agree:\n",
        "        if language not in supported_languages:\n",
        "            print(f\"Language you put {language} in is not in our Supported Languages, please choose from dropdown\")\n",
        "            return None\n",
        "\n",
        "        # پیش‌بینی زبان متن ورودی با استفاده از یک مدل تشخیص زبان\n",
        "        language_predicted = langid.classify(prompt)[0].strip()\n",
        "\n",
        "\n",
        "        if len(prompt) > 15:\n",
        "            if language_predicted != language and not no_lang_auto_detect:\n",
        "                print(f\"It looks like your text isn’t the language you chose , if you’re sure the text is the same language you chose, please check disable language auto-detection checkbox\")\n",
        "                return None\n",
        "\n",
        "        speaker_wav = audio_file_pth\n",
        "\n",
        "        # Filtering for microphone input\n",
        "        lowpassfilter = denoise = trim = loudness = True\n",
        "        lowpass_highpass = \"lowpass=8000,highpass=75,\" if lowpassfilter else \"\"\n",
        "        trim_silence = \"areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,areverse,silenceremove=start_periods=1:start_silence=0:start_threshold=0.02,\" if trim else \"\"\n",
        "\n",
        "        if voice_cleanup:\n",
        "            try:\n",
        "                out_filename = speaker_wav + str(uuid.uuid4()) + \".wav\"\n",
        "                shell_command = f\"./ffmpeg -y -i {speaker_wav} -af {lowpass_highpass}{trim_silence} {out_filename}\".split(\" \")\n",
        "                subprocess.run(shell_command, capture_output=False, text=True, check=True)\n",
        "                speaker_wav = out_filename\n",
        "                print(\"Filtered microphone input\")\n",
        "            except subprocess.CalledProcessError:\n",
        "                print(\"Error: failed filtering, use original microphone input\")\n",
        "\n",
        "        if len(prompt) < 2:\n",
        "            print(\"Please give a longer prompt text\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            prompt = re.sub(\"([^\\x00-\\x7F]|\\w)(\\.|\\。|\\?)\", r\"\\1 \\2\\2\", prompt)\n",
        "            print(\"Generating new audio...\")\n",
        "            t0 = time.time() # زمان شروع فرآیند تولید صوت\n",
        "            out = model.inference(\n",
        "                prompt,\n",
        "                language,\n",
        "    *model.get_conditioning_latents(audio_path=speaker_wav, gpt_cond_len=15, gpt_cond_chunk_len=2, max_ref_length=30),\n",
        "                repetition_penalty=3.5,  # جریمه‌ی تکرار پایین‌تر برای خلاقیت بیشتر\n",
        "                temperature=2.0,          # دمای بالا برای خلاقیت و تنوع بیشتر\n",
        "            )\n",
        "            inference_time = time.time() - t0\n",
        "            print(f\"Time to generate audio: {round(inference_time * 1000)} milliseconds\")\n",
        "            real_time_factor = (time.time() - t0) / out['wav'].shape[-1] * 24000\n",
        "            print(f\"Real-time factor (RTF): {real_time_factor}\")\n",
        "            torchaudio.save(output_file, torch.tensor(out[\"wav\"]).unsqueeze(0), 24000)\n",
        "            print(\"Audio saved to  \"+output_file)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            if \"device-side assert\" in str(e):\n",
        "                print(f\"Exit due to: Unrecoverable exception caused by language:{language} prompt:{prompt}\")\n",
        "                print(\"Unhandled Exception encounter, please retry in a minute\")\n",
        "                print(\"Cuda device-assert Runtime encountered need restart\")\n",
        "                if not DEVICE_ASSERT_DETECTED:\n",
        "                    DEVICE_ASSERT_DETECTED = 1\n",
        "                    DEVICE_ASSERT_PROMPT = prompt\n",
        "                    DEVICE_ASSERT_LANG = language\n",
        "\n",
        "                error_time = datetime.datetime.now().strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
        "                error_data = [\n",
        "                    error_time,\n",
        "                    prompt,\n",
        "                    language,\n",
        "                    audio_file_pth,\n",
        "                    mic_file_path,\n",
        "                    use_mic,\n",
        "                    voice_cleanup,\n",
        "                    no_lang_auto_detect,\n",
        "                    agree,\n",
        "                ]\n",
        "                error_data = [str(e) if type(e) != str else e for e in error_data]\n",
        "                print(error_data)\n",
        "                write_io = StringIO()\n",
        "                csv.writer(write_io).writerows([error_data])\n",
        "                csv_upload = write_io.getvalue().encode()\n",
        "\n",
        "                filename = error_time + \"_\" + str(uuid.uuid4()) + \".csv\"\n",
        "                print(\"Writing error csv\")\n",
        "                error_api = HfApi()\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=csv_upload,\n",
        "                    path_in_repo=filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                print(\"Writing error reference audio\")\n",
        "                speaker_filename = error_time + \"_reference_\" + str(uuid.uuid4()) + \".wav\"\n",
        "                error_api.upload_file(\n",
        "                    path_or_fileobj=speaker_wav,\n",
        "                    path_in_repo=speaker_filename,\n",
        "                    repo_id=\"coqui/xtts-flagged-dataset\",\n",
        "                    repo_type=\"dataset\",\n",
        "                )\n",
        "\n",
        "                space = api.get_space_runtime(repo_id=repo_id)\n",
        "                if space.stage != \"BUILDING\":\n",
        "                    api.restart_space(repo_id=repo_id)\n",
        "                else:\n",
        "                    print(\"TRIED TO RESTART but space is building\")\n",
        "            else:\n",
        "                if \"Failed to decode\" in str(e):\n",
        "                    print(\"Speaker encoding error\", str(e))\n",
        "                else:\n",
        "                    print(\"RuntimeError: non device-side assert error:\", str(e))\n",
        "                return None\n",
        "\n",
        "        return output_file\n"
      ],
      "metadata": {
        "id": "G-w6GgCEUGRW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_speech(prompt, language_code, chunk_id):\n",
        "    output_file = f\"chunk_{chunk_id}.wav\"\n",
        "    language_code = \"en\"\n",
        "    audio_file_path = '/content/1.mp3'  # Path to reference audio file if needed\n",
        "    mic_file_path = None  # Path to microphone recorded audio if needed\n",
        "    use_microphone = False\n",
        "    voice_cleanup = True\n",
        "    disable_lang_auto_detect = True\n",
        "\n",
        "    return text_to_speech(\n",
        "        prompt=prompt,\n",
        "        language=language_code,\n",
        "        audio_file_pth=audio_file_path,\n",
        "        mic_file_path=mic_file_path,\n",
        "        use_mic=use_microphone,\n",
        "        voice_cleanup=voice_cleanup,\n",
        "        no_lang_auto_detect=disable_lang_auto_detect,\n",
        "        agree=True,\n",
        "        output_file= output_file)"
      ],
      "metadata": {
        "id": "hOL9GLg4YSmh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to combine multiple audio files into one\n",
        "def combine_audio_files(audio_files, output_file):\n",
        "\n",
        "    with open(\"file_list.txt\", \"w\") as file_list:\n",
        "      for audio_file in audio_files:\n",
        "          file_list.write(f\"file '{audio_file}'\\n\")\n",
        "\n",
        "    command = [\"ffmpeg\", \"-f\", \"concat\", \"-safe\", \"0\", \"-i\", \"file_list.txt\", \"-c\", \"copy\", output_file]\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "        print(f\"Audio files successfully combined into {output_file}\")\n",
        "        print(result.stdout)\n",
        "        print(result.stderr)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error occurred during combining audio files: {e}\")\n",
        "        print(e.stdout)\n",
        "        print(e.stderr)\n",
        "\n",
        "    for audio_file in audio_files:\n",
        "      os.remove(audio_file)\n",
        "\n",
        "    # with open(output_file, 'wb') as outfile:\n",
        "    #     for audio_file in audio_files:\n",
        "    #         with open(audio_file, 'rb') as infile:\n",
        "    #             outfile.write(infile.read())\n",
        "            # Clean up temporary files\n",
        "            # os.remove(audio_file)"
      ],
      "metadata": {
        "id": "FFhNU1zhXu52"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files = [\"chunk_1.wav\", \"chunk_2.wav\",\"chunk_3.wav\"]\n",
        "output_file = \"combined_output.wav\"\n",
        "combine_audio_files(audio_files, output_file)"
      ],
      "metadata": {
        "id": "iinizpE4cZwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_to_speech(text, language_code):\n",
        "    # Split text into chunks of 200 characters\n",
        "    chunks = split_text(text)\n",
        "\n",
        "    all_audio_files = []\n",
        "\n",
        "\n",
        "    if os.path.isfile(\"combined_output.wav\"):\n",
        "      os.remove(\"combined_output.wav\")\n",
        "\n",
        "\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "      temp_file = generate_speech(chunk, language_code, idx + 1)\n",
        "      if os.path.exists(temp_file):\n",
        "          all_audio_files.append(temp_file)\n",
        "      else:\n",
        "          print(f\"Failed to generate audio for chunk {idx + 1}.\")\n",
        "\n",
        "    # Combine all audio files into one\n",
        "    if all_audio_files:\n",
        "        combined_audio = \"combined_output.wav\"\n",
        "        combine_audio_files(all_audio_files, combined_audio)\n",
        "        print(f\"All audio files combined into {combined_audio}\")\n",
        "    else:\n",
        "        print(\"No audio files to combine.\")"
      ],
      "metadata": {
        "id": "qn9SMN3uUVWN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "prompt_text = \"\"\"Hey everyone, welcome back to the channel! Today, I want to talk about a topic that's been on my mind for a while: motivation versus discipline. We all know that motivation is great when it hits us, but there's a catch: you can’t always count on it. It tends to come at the most random times, like at 3 AM when you’re about to go back to bed but suddenly feel the urge to exercise, or in the middle of a party when you're looking at yourself in the mirror.\n",
        "\n",
        "So, what’s the answer? Discipline. It took me 18 years to figure this out. I started with motivation and watched countless videos on discipline, from big channels to smaller ones, in both Persian and English. And let me tell you, about 90% of them were pretty much useless. It wasn’t because they didn’t try, but because they tackled the subject all wrong. My goal with this video is to give you real, useful advice on how to integrate discipline into your life—no clickbait, just genuine help.\"\"\"\n",
        "\n",
        "process_text_to_speech(prompt_text, language_code=\"en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZUz9btqUaVX",
        "outputId": "5227c81c-b9e8-4fdd-e222-61e67a8cb8f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered microphone input\n",
            "Generating new audio...\n",
            "Time to generate audio: 4305 milliseconds\n",
            "Real-time factor (RTF): 0.29810356248604847\n",
            "Audio saved to  chunk_1.wav\n",
            "Filtered microphone input\n",
            "Generating new audio...\n",
            "Time to generate audio: 3240 milliseconds\n",
            "Real-time factor (RTF): 0.23732424597255886\n",
            "Audio saved to  chunk_2.wav\n",
            "Filtered microphone input\n",
            "Generating new audio...\n",
            "Time to generate audio: 4392 milliseconds\n",
            "Real-time factor (RTF): 0.23354636426007147\n",
            "Audio saved to  chunk_3.wav\n",
            "Filtered microphone input\n",
            "Generating new audio...\n",
            "Time to generate audio: 3193 milliseconds\n",
            "Real-time factor (RTF): 0.2625676558205956\n",
            "Audio saved to  chunk_4.wav\n",
            "Filtered microphone input\n",
            "Generating new audio...\n",
            "Time to generate audio: 3975 milliseconds\n",
            "Real-time factor (RTF): 0.30374401283147573\n",
            "Audio saved to  chunk_5.wav\n",
            "Audio files successfully combined into combined_output.wav\n",
            "\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Guessed Channel Layout for Input Stream #0.0 : mono\n",
            "Input #0, concat, from 'file_list.txt':\n",
            "  Duration: N/A, start: 0.000000, bitrate: 384 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Output #0, wav, to 'combined_output.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, mono, s16, 384 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "size=       4kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
            "size=    3382kB time=00:01:12.11 bitrate= 384.2kbits/s speed= 861x    \n",
            "video:0kB audio:3382kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002252%\n",
            "\n",
            "All audio files combined into combined_output.wav\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}